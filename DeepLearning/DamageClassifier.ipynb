{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8GY-I6zktaPg",
        "outputId": "00fc702e-550d-4130-cc00-ff2574c99284"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.9/dist-packages (2.0.0+cu118)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from torch) (3.10.7)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.9/dist-packages (from torch) (1.11.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.9/dist-packages (from torch) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.9/dist-packages (from torch) (2.0.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.9/dist-packages (from torch) (4.5.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.9/dist-packages (from torch) (3.0)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.9/dist-packages (from triton==2.0.0->torch) (16.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.9/dist-packages (from triton==2.0.0->torch) (3.25.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.9/dist-packages (from jinja2->torch) (2.1.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.9/dist-packages (from sympy->torch) (1.3.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.9/dist-packages (0.15.1+cu118)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.9/dist-packages (from torchvision) (1.22.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from torchvision) (2.27.1)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.9/dist-packages (from torchvision) (8.4.0)\n",
            "Requirement already satisfied: torch==2.0.0 in /usr/local/lib/python3.9/dist-packages (from torchvision) (2.0.0+cu118)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.9/dist-packages (from torch==2.0.0->torchvision) (1.11.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from torch==2.0.0->torchvision) (3.10.7)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.9/dist-packages (from torch==2.0.0->torchvision) (3.1.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.9/dist-packages (from torch==2.0.0->torchvision) (4.5.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.9/dist-packages (from torch==2.0.0->torchvision) (3.0)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.9/dist-packages (from torch==2.0.0->torchvision) (2.0.0)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.9/dist-packages (from triton==2.0.0->torch==2.0.0->torchvision) (16.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.9/dist-packages (from triton==2.0.0->torch==2.0.0->torchvision) (3.25.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests->torchvision) (3.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests->torchvision) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests->torchvision) (2.0.12)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests->torchvision) (1.26.15)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.9/dist-packages (from jinja2->torch==2.0.0->torchvision) (2.1.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.9/dist-packages (from sympy->torch==2.0.0->torchvision) (1.3.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.9/dist-packages (4.65.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: google-colab in /usr/local/lib/python3.9/dist-packages (1.0.0)\n",
            "Requirement already satisfied: pandas>=1.1.0 in /usr/local/lib/python3.9/dist-packages (from google-colab) (1.4.4)\n",
            "Requirement already satisfied: ipykernel~=5.5.6 in /usr/local/lib/python3.9/dist-packages (from google-colab) (5.5.6)\n",
            "Requirement already satisfied: portpicker~=1.3.1 in /usr/local/lib/python3.9/dist-packages (from google-colab) (1.3.9)\n",
            "Requirement already satisfied: ipython~=7.34.0 in /usr/local/lib/python3.9/dist-packages (from google-colab) (7.34.0)\n",
            "Requirement already satisfied: tornado~=6.2 in /usr/local/lib/python3.9/dist-packages (from google-colab) (6.2)\n",
            "Requirement already satisfied: requests>=2.27.0 in /usr/local/lib/python3.9/dist-packages (from google-colab) (2.27.1)\n",
            "Requirement already satisfied: notebook==6.4.8 in /usr/local/lib/python3.9/dist-packages (from google-colab) (6.4.8)\n",
            "Requirement already satisfied: google-auth>=1.17.2 in /usr/local/lib/python3.9/dist-packages (from google-colab) (2.17.1)\n",
            "Requirement already satisfied: pyzmq>=17 in /usr/local/lib/python3.9/dist-packages (from notebook==6.4.8->google-colab) (23.2.1)\n",
            "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.9/dist-packages (from notebook==6.4.8->google-colab) (0.2.0)\n",
            "Requirement already satisfied: nbconvert in /usr/local/lib/python3.9/dist-packages (from notebook==6.4.8->google-colab) (6.5.4)\n",
            "Requirement already satisfied: nest-asyncio>=1.5 in /usr/local/lib/python3.9/dist-packages (from notebook==6.4.8->google-colab) (1.5.6)\n",
            "Requirement already satisfied: Send2Trash>=1.8.0 in /usr/local/lib/python3.9/dist-packages (from notebook==6.4.8->google-colab) (1.8.0)\n",
            "Requirement already satisfied: terminado>=0.8.3 in /usr/local/lib/python3.9/dist-packages (from notebook==6.4.8->google-colab) (0.17.1)\n",
            "Requirement already satisfied: jupyter-core>=4.6.1 in /usr/local/lib/python3.9/dist-packages (from notebook==6.4.8->google-colab) (5.3.0)\n",
            "Requirement already satisfied: traitlets>=4.2.1 in /usr/local/lib/python3.9/dist-packages (from notebook==6.4.8->google-colab) (5.7.1)\n",
            "Requirement already satisfied: jupyter-client>=5.3.4 in /usr/local/lib/python3.9/dist-packages (from notebook==6.4.8->google-colab) (6.1.12)\n",
            "Requirement already satisfied: prometheus-client in /usr/local/lib/python3.9/dist-packages (from notebook==6.4.8->google-colab) (0.16.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.9/dist-packages (from notebook==6.4.8->google-colab) (3.1.2)\n",
            "Requirement already satisfied: nbformat in /usr/local/lib/python3.9/dist-packages (from notebook==6.4.8->google-colab) (5.8.0)\n",
            "Requirement already satisfied: argon2-cffi in /usr/local/lib/python3.9/dist-packages (from notebook==6.4.8->google-colab) (21.3.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from google-auth>=1.17.2->google-colab) (5.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.9/dist-packages (from google-auth>=1.17.2->google-colab) (4.9)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.9/dist-packages (from google-auth>=1.17.2->google-colab) (1.16.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.9/dist-packages (from google-auth>=1.17.2->google-colab) (0.2.8)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.9/dist-packages (from ipython~=7.34.0->google-colab) (4.4.2)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.9/dist-packages (from ipython~=7.34.0->google-colab) (2.14.0)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.9/dist-packages (from ipython~=7.34.0->google-colab) (0.1.6)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from ipython~=7.34.0->google-colab) (3.0.38)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.9/dist-packages (from ipython~=7.34.0->google-colab) (4.8.0)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.9/dist-packages (from ipython~=7.34.0->google-colab) (67.6.1)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.9/dist-packages (from ipython~=7.34.0->google-colab) (0.2.0)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.9/dist-packages (from ipython~=7.34.0->google-colab) (0.7.5)\n",
            "Collecting jedi>=0.16\n",
            "  Downloading jedi-0.18.2-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m28.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.9/dist-packages (from pandas>=1.1.0->google-colab) (2022.7.1)\n",
            "Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.9/dist-packages (from pandas>=1.1.0->google-colab) (1.22.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.9/dist-packages (from pandas>=1.1.0->google-colab) (2.8.2)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests>=2.27.0->google-colab) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests>=2.27.0->google-colab) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests>=2.27.0->google-colab) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests>=2.27.0->google-colab) (3.4)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /usr/local/lib/python3.9/dist-packages (from jedi>=0.16->ipython~=7.34.0->google-colab) (0.8.3)\n",
            "Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.9/dist-packages (from jupyter-core>=4.6.1->notebook==6.4.8->google-colab) (3.2.0)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.9/dist-packages (from pexpect>4.3->ipython~=7.34.0->google-colab) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.9/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython~=7.34.0->google-colab) (0.2.6)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.9/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=1.17.2->google-colab) (0.4.8)\n",
            "Requirement already satisfied: argon2-cffi-bindings in /usr/local/lib/python3.9/dist-packages (from argon2-cffi->notebook==6.4.8->google-colab) (21.2.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.9/dist-packages (from jinja2->notebook==6.4.8->google-colab) (2.1.2)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.9/dist-packages (from nbconvert->notebook==6.4.8->google-colab) (0.7.1)\n",
            "Requirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.9/dist-packages (from nbconvert->notebook==6.4.8->google-colab) (0.8.4)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.9/dist-packages (from nbconvert->notebook==6.4.8->google-colab) (6.0.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.9/dist-packages (from nbconvert->notebook==6.4.8->google-colab) (4.11.2)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.9/dist-packages (from nbconvert->notebook==6.4.8->google-colab) (4.9.2)\n",
            "Requirement already satisfied: entrypoints>=0.2.2 in /usr/local/lib/python3.9/dist-packages (from nbconvert->notebook==6.4.8->google-colab) (0.4)\n",
            "Requirement already satisfied: tinycss2 in /usr/local/lib/python3.9/dist-packages (from nbconvert->notebook==6.4.8->google-colab) (1.2.1)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.9/dist-packages (from nbconvert->notebook==6.4.8->google-colab) (1.5.0)\n",
            "Requirement already satisfied: jupyterlab-pygments in /usr/local/lib/python3.9/dist-packages (from nbconvert->notebook==6.4.8->google-colab) (0.2.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.9/dist-packages (from nbconvert->notebook==6.4.8->google-colab) (23.0)\n",
            "Requirement already satisfied: nbclient>=0.5.0 in /usr/local/lib/python3.9/dist-packages (from nbconvert->notebook==6.4.8->google-colab) (0.7.3)\n",
            "Requirement already satisfied: jsonschema>=2.6 in /usr/local/lib/python3.9/dist-packages (from nbformat->notebook==6.4.8->google-colab) (4.3.3)\n",
            "Requirement already satisfied: fastjsonschema in /usr/local/lib/python3.9/dist-packages (from nbformat->notebook==6.4.8->google-colab) (2.16.3)\n",
            "Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.9/dist-packages (from jsonschema>=2.6->nbformat->notebook==6.4.8->google-colab) (22.2.0)\n",
            "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /usr/local/lib/python3.9/dist-packages (from jsonschema>=2.6->nbformat->notebook==6.4.8->google-colab) (0.19.3)\n",
            "Requirement already satisfied: cffi>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from argon2-cffi-bindings->argon2-cffi->notebook==6.4.8->google-colab) (1.15.1)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.9/dist-packages (from beautifulsoup4->nbconvert->notebook==6.4.8->google-colab) (2.4)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.9/dist-packages (from bleach->nbconvert->notebook==6.4.8->google-colab) (0.5.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.9/dist-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi->notebook==6.4.8->google-colab) (2.21)\n",
            "Installing collected packages: jedi\n",
            "Successfully installed jedi-0.18.2\n"
          ]
        }
      ],
      "source": [
        "# import and install packages\n",
        "\n",
        "!pip3 install torch\n",
        "!pip3 install torchvision\n",
        "!pip3 install tqdm\n",
        "!pip install google-colab\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from torchvision import transforms, utils, datasets\n",
        "from tqdm import tqdm\n",
        "from torch.nn.parameter import Parameter\n",
        "import pdb\n",
        "import torchvision\n",
        "import os\n",
        "import gzip\n",
        "import tarfile\n",
        "import gc\n",
        "from google.colab import files\n",
        "from google.colab import drive\n",
        "import json\n",
        "from PIL import Image, ImageDraw\n",
        "from IPython.core.ultratb import AutoFormattedTB\n",
        "from PIL import Image\n",
        "import glob\n",
        "__ITB__ = AutoFormattedTB(mode = 'Verbose',color_scheme='LightBg', tb_offset = 1)\n",
        "\n",
        "# assert torch.cuda.is_available(), \"You need to request a GPU from Runtime > Change Runtime\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hfeTnKCNH4iM"
      },
      "source": [
        "Load Images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OjgZO1pOY8ll",
        "outputId": "f68df311-bb3b-4142-c11d-c6f37d8db1b4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "drive.mount('/content/drive')\n",
        "path_coco = \"/content/damage_coco\"\n",
        "path_robo = \"/content/damage_robo\"\n",
        "\n",
        "if not os.path.exists(path_coco):\n",
        "    os.makedirs(path_coco)\n",
        "if not os.path.exists(path_robo):\n",
        "    os.makedirs(path_robo)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "xy4aiw2BY-kI"
      },
      "outputs": [],
      "source": [
        "!unzip -q /content/drive/MyDrive/College/3.\\ Junior/Winter\\ Semester/CS\\ 474/Final\\ DL/Car_Data/damage_coco.zip -d /content/damage_coco\n",
        "!unzip -q /content/drive/MyDrive/College/3.\\ Junior/Winter\\ Semester/CS\\ 474/Final\\ DL/Car_Data/damage_roboflow.zip -d /content/damage_robo\n",
        "# !unzip  -q /content/drive/MyDrive/DL_Project/damage_coco.zip -d /content/damage_coco\n",
        "# !unzip -q /content/drive/MyDrive/DL_Project/damage_roboflow.zip -d /content/damage_robo"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def resize(filename):\n",
        "  root_folder = \"/content/damage_coco/train\"\n",
        "  for subdir, dirs, files in os.walk(root_folder):\n",
        "      for file in files:\n",
        "          # get the file extension and check if it's an image\n",
        "          ext = os.path.splitext(file)[-1].lower()\n",
        "          \n",
        "          if ext in ['.jpg', '.jpeg', '.png', '.bmp']:\n",
        "              # get the full path of the image file\n",
        "              file_path = os.path.join(subdir, file)\n",
        "              \n",
        "              # open the image and resize it to a smaller size\n",
        "              img = Image.open(file_path)\n",
        "              os.remove(file_path)\n",
        "              img = img.resize((256, 256), resample=Image.LANCZOS)\n",
        "              \n",
        "              # save the compressed image in the same folder with a new name\n",
        "              new_file_name = os.path.splitext(file)[0] + ext\n",
        "              img.save(os.path.join(subdir, new_file_name), quality=70)\n"
      ],
      "metadata": {
        "id": "w_RWSrQxjdg6"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "cRnTn3Beat17"
      },
      "outputs": [],
      "source": [
        "# resize damage_coco training images\n",
        "resize(\"/content/damage_coco/train\")\n",
        "\n",
        "# resize damage_coco test images\n",
        "resize(\"/content/damage_coco/test\")\n",
        "\n",
        "# resize damage_roboflow training images\n",
        "resize(\"/content/damage_roboflow/train\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "GVQznnxK3VI7"
      },
      "outputs": [],
      "source": [
        "# !rmdir /content/damage_coco/val/.ipynb_checkpoints/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "2LGhlA3ffv2W"
      },
      "outputs": [],
      "source": [
        "# make a new file path for the training images for the data loader\n",
        "path_coco_train = \"/content/damage_coco/train/0\"\n",
        "path_coco_test = \"/content/damage_coco/test/0\"\n",
        "\n",
        "if not os.path.exists(path_coco_train):\n",
        "    os.makedirs(path_coco_train)\n",
        "if not os.path.exists(path_coco_test):\n",
        "    os.makedirs(path_coco_test)\n",
        "\n",
        "\n",
        "path_robo_train = \"/content/damage_robo/train/0\"\n",
        "path_robo_test = \"/content/damage_robo/test/0\"\n",
        "\n",
        "if not os.path.exists(path_robo_train):\n",
        "    os.makedirs(path_robo_train)\n",
        "if not os.path.exists(path_robo_test):\n",
        "    os.makedirs(path_robo_test)\n",
        "\n",
        "# move training images:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9tCXYxntf6sE",
        "outputId": "d85c5b45-5df3-45a8-bbaa-7c9c6d60f1d1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/bin/bash: rmdir/content/damage_coco/img: No such file or directory\n"
          ]
        }
      ],
      "source": [
        "!mv /content/damage_coco/train/*.jpg /content/damage_coco/train/0\n",
        "!mv /content/damage_coco/test/*.jpg /content/damage_coco/test/0\n",
        "\n",
        "!mv /content/damage_robo/train/test_set_*.jpg /content/damage_robo/test/0\n",
        "!mv /content/damage_robo/train/*.jpg /content/damage_robo/train/0\n",
        "\n",
        "!rm /content/damage_coco/img/*.jpg\n",
        "!rmdir/content/damage_coco/img"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2om36qUStIuN",
        "outputId": "a484e019-4fe4-4f93-9017-c9d0b13599ac"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "gYqIbPMO8TzI"
      },
      "outputs": [],
      "source": [
        "# STANFORD ANNOTATION COCO DATA\n",
        "ratio = 4\n",
        "size = 256\n",
        "width, height = size, size\n",
        "test_ids = [11, 12, 28, 45, 60, 66, 67, 72]\n",
        "\n",
        "# make a new file path for the training masks for the data loader\n",
        "coco_mask_train = \"/content/damage_coco/masks_train/0\"\n",
        "coco_mask_test = \"/content/damage_coco/masks_test/0\"\n",
        "if not os.path.exists(coco_mask_train):\n",
        "    os.makedirs(coco_mask_train)\n",
        "if not os.path.exists(coco_mask_test):\n",
        "    os.makedirs(coco_mask_test)\n",
        "\n",
        "\n",
        "# Load the JSON data\n",
        "with open('/content/damage_coco/train/COCO_mul_train_annos.json') as f:\n",
        "    data = json.load(f)\n",
        "\n",
        "# Create an empty mask\n",
        "mask = np.zeros((height, width), dtype=np.uint8)\n",
        "last_image = 0\n",
        "damage_count = 0\n",
        "\n",
        "for annotation in data['annotations']:\n",
        "  # print(last_image)\n",
        "  image_id = annotation['image_id']\n",
        "  if last_image == image_id:\n",
        "    damage_count += 1\n",
        "\n",
        "  else:\n",
        "    # save the previous mask\n",
        "    if image_id in test_ids:\n",
        "      folder = \"masks_test\"\n",
        "    else:\n",
        "      folder = \"masks_train\"\n",
        "    name = '/content/damage_coco/' + folder + '/0/mask'+ \\\n",
        "            str(image_id)+'_'+str(damage_count)+'.png'\n",
        "    # print(name)\n",
        "\n",
        "    # Convert the array to an image and save it\n",
        "    img = Image.fromarray(mask*255)\n",
        "    img.save(name)\n",
        "    # img.show()\n",
        "    if last_image == 13:\n",
        "      break\n",
        "\n",
        "    # Create an empty mask\n",
        "    mask = np.zeros((height, width), dtype=np.uint8)\n",
        "    last_image = annotation['image_id']\n",
        "    damage_count = 0\n",
        "\n",
        "  # get damage labels\n",
        "  box = annotation['bbox']\n",
        "  x, y, dx, dy = [b // ratio for b in box]\n",
        "  # print(\"box:\", box)\n",
        "  # print(\"xyd:\", x, y, dx, dy)\n",
        "  mask[x:x+dx+1, y:y+dy+1] +=1\n",
        "\n",
        "# STANFORD ANNOTATION COCO DATA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "bJ66AHZY-_a8"
      },
      "outputs": [],
      "source": [
        "# ROBOFLOW ANNOTATION DATA\n",
        "ratio = 2\n",
        "size = 256\n",
        "width, height = size, size\n",
        "\n",
        "# make a new file path for the training masks for the data loader\n",
        "robo_mask_train = \"/content/damage_robo/masks_train/0\"\n",
        "robot_mask_test = \"/content/damage_robo/masks_test/0\"\n",
        "if not os.path.exists(robo_mask_train):\n",
        "    os.makedirs(robo_mask_train)\n",
        "if not os.path.exists(robot_mask_test):\n",
        "    os.makedirs(robot_mask_test)\n",
        "\n",
        "\n",
        "# Load the JSON data\n",
        "with open('/content/damage_robo/train/_annotations.coco.json') as f:\n",
        "    data = json.load(f)\n",
        "\n",
        "image_id = 0\n",
        "\n",
        "for annotation in data['annotations']:\n",
        "  # Create an empty mask\n",
        "  mask = np.zeros((height, width), dtype=np.uint8)\n",
        "  image_id = annotation['image_id']\n",
        "\n",
        "  # get damage labels\n",
        "  box = annotation['bbox']\n",
        "  x, y, dx, dy = [int(b // ratio) for b in box]\n",
        "  mask[x:x+dx+1, y:y+dy+1] +=1\n",
        "\n",
        "  # determine if the data is for testing or training\n",
        "  meta_image = next((img for img in data['images'] if img['id'] == image_id), None)\n",
        "  if meta_image and meta_image['file_name'].startswith('test'):\n",
        "      folder_name = 'masks_test'\n",
        "  else:\n",
        "      folder_name = 'masks_train'\n",
        "\n",
        "  # save the mask\n",
        "  name = '/content/damage_robo/' + folder_name + '/0/mask'+ \\\n",
        "          str(image_id) + '.png'\n",
        "\n",
        "  # Convert the array to an image and save it\n",
        "  img = Image.fromarray(mask*255)\n",
        "  img.save(name)\n",
        "  \n",
        "# ROBOFLOW ANNOTATION DATA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "_zjUpWtZHxwU"
      },
      "outputs": [],
      "source": [
        "class DamagedDataset(Dataset):\n",
        "  def __init__(self, root1, root2=None, download=True, size=256, train=True):\n",
        "    postfix = 'train' if train else 'test'\n",
        "    label_post = 'masks_train' if train else 'masks_test'\n",
        "    print(os.path.join(root1, postfix))\n",
        "\n",
        "    self.dataset_folder = torchvision.datasets.ImageFolder(os.path.join(root1, postfix), \n",
        "                                                           transform = transforms.Compose([\n",
        "                                                               transforms.Resize(size),\n",
        "                                                               transforms.ToTensor()\n",
        "                                                               ]))\n",
        "    self.label_folder = torchvision.datasets.ImageFolder(os.path.join(root1, label_post), \n",
        "                                                         transform = transforms.Compose([\n",
        "                                                             transforms.Resize(size),\n",
        "                                                             transforms.ToTensor()\n",
        "                                                             ]))\n",
        "    \n",
        "    if root2 is not None:\n",
        "      self.dataset_folder2 = torchvision.datasets.ImageFolder(os.path.join(root2, postfix), \n",
        "                                                            transform = transforms.Compose([\n",
        "                                                                transforms.Resize(size),\n",
        "                                                                transforms.ToTensor()\n",
        "                                                                ]))\n",
        "      self.label_folder2 = torchvision.datasets.ImageFolder(os.path.join(root2, label_post), \n",
        "                                                          transform = transforms.Compose([\n",
        "                                                              transforms.Resize(size),\n",
        "                                                              transforms.ToTensor()\n",
        "                                                              ]))\n",
        "      \n",
        "      # Combine the two dataset and label folders\n",
        "      self.dataset_folder = torch.utils.data.ConcatDataset([self.dataset_folder, self.dataset_folder2])\n",
        "      self.label_folder = torch.utils.data.ConcatDataset([self.label_folder, self.label_folder2])\n",
        "\n",
        "\n",
        "  def __getitem__(self,index):\n",
        "    img = self.dataset_folder[index]\n",
        "    label = self.label_folder[index]\n",
        "    return img[0], label[0][0]\n",
        "  \n",
        "  \n",
        "  def __len__(self):\n",
        "    return len(self.dataset_folder)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fbpCZsjvpzoB"
      },
      "source": [
        "end data loading\n",
        ".---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
        "Neural Net"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "5ZM4V6VKpxKA"
      },
      "outputs": [],
      "source": [
        "class ConvBlock(nn.Module):\n",
        "  def __init__(self, in_channels, out_channels, up_sample=False):\n",
        "    super(ConvBlock, self).__init__()\n",
        "    self.conv1 = nn.Conv2d(in_channels, out_channels, (3,3), padding=(1,1))\n",
        "    self.conv2 = nn.Conv2d(out_channels, out_channels, (3,3), padding=(1,1))\n",
        "    self.up_sample = up_sample\n",
        "    if up_sample:    \n",
        "      # Up sample with up-conv 2x2, doubling along each dimension\n",
        "      self.up = nn.ConvTranspose2d(out_channels, out_channels//2, 2, stride=2)\n",
        "    # We do not want to down sample in the block, since we need the non-down-sampled output for skip connections\n",
        "\n",
        "  def forward(self, input):\n",
        "    x = F.relu(self.conv1(input))\n",
        "    x = F.relu(self.conv2(x))\n",
        "    if self.up_sample:\n",
        "      x = self.up(x)\n",
        "    return x\n",
        "\n",
        "class DamageDetection(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(DamageDetection, self).__init__()\n",
        "    # Downsample convolution blocks\n",
        "    self.dblock1 = ConvBlock(3, 32)\n",
        "    self.dblock2 = ConvBlock(32, 64)\n",
        "    self.dblock3 = ConvBlock(64, 128)\n",
        "    self.dblock4 = ConvBlock(128, 256)\n",
        "    # Upsample convolution blocks\n",
        "    self.ublock1 = ConvBlock(256, 512, True)\n",
        "    # The next 4 blocks have doubled input channels due to concatenation of skip connections\n",
        "    self.ublock2 = ConvBlock(512, 256, True)\n",
        "    self.ublock3 = ConvBlock(256, 128, True)\n",
        "    self.ublock4 = ConvBlock(128, 64, True)\n",
        "    # Output \"block\"\n",
        "    self.convf1 = nn.Conv2d(64, 32, (3,3), padding=(1,1))\n",
        "    self.convf2 = nn.Conv2d(32, 32, (3,3), padding=(1,1))\n",
        "    self.convf3 = nn.Conv2d(32, 2, (1,1), padding=(0,0))\n",
        "\n",
        "    self.down = nn.MaxPool2d(2)\n",
        " \n",
        "  def forward(self, input):\n",
        "    # Save the last feature maps on each level! Pass an instance forward, but keep the variable referencing the same feature map for concatenation\n",
        "    l1 = self.dblock1(input)\n",
        "    l2 = self.dblock2(self.down(l1))\n",
        "    l3 = self.dblock3(self.down(l2))\n",
        "    l4 = self.dblock4(self.down(l3))\n",
        "    # Concatinate l1 - l4 on inputs across the U in reverse order, matching sizes\n",
        "    u = self.ublock1(self.down(l4))\n",
        "    u = self.ublock2(torch.cat((l4, u), dim=1))\n",
        "    u = self.ublock3(torch.cat((l3, u), dim=1))\n",
        "    u = self.ublock4(torch.cat((l2, u), dim=1))\n",
        "    out = F.relu(self.convf1(torch.cat((l1, u), dim=1)))\n",
        "    out = F.relu(self.convf2(out))\n",
        "    out = self.convf3(out)\n",
        "    return out"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iH_B7K3mIcrI"
      },
      "source": [
        "Initialize Classifier"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C0kNY6BvImG9"
      },
      "source": [
        "Create datasets, dataloaders and neural network"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BQCBsgD5ImRT",
        "outputId": "36592797-f46f-4881-e8bd-13c52d7ee67e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/damage_coco/train\n",
            "/content/damage_coco/test\n"
          ]
        }
      ],
      "source": [
        "# TODO load masks so that they can load properly with the DamagedDataset class\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Initialize Datasets\n",
        "path_coco = '/content/damage_coco'\n",
        "path_robo = '/content/damage_robo'\n",
        "train_dataset = DamagedDataset(path_coco, path_robo, train = True)\n",
        "val_dataset = DamagedDataset(path_coco, path_robo, train = False)\n",
        "\n",
        "# Initialize Model\n",
        "model = DamageDetection()\n",
        "model = model.cuda()\n",
        " # Initialize Objective and Optimizer and other parameters\n",
        "objective = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=1e-4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "12xZPcG7qJyM"
      },
      "outputs": [],
      "source": [
        "losses = []\n",
        "accuracies = []\n",
        "validations = []\n",
        "val_accs = []\n",
        "pred_img = []"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "daoFJttlqLop"
      },
      "source": [
        "Train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "64Iv-WTkqMhc",
        "outputId": "171d9ffb-339f-49f5-9ad8-c073d712aa0b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.031044608\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch0, loss:0.6332, accuracy:0.915 val_acc:0.000:   0%|          | 1/264 [00:02<08:59,  2.05s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)\n",
            "\u001b[0;32m<ipython-input-16-af93d8120b1f>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0=<torch.utils.data.dataloader._MultiProcessingDataLoaderIter object>)\u001b[0m\n",
            "\u001b[1;32m     42\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m20\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m     43\u001b[0m           \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mobjective\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0m        \u001b[0;36mglobal\u001b[0m \u001b[0;36mval\u001b[0m \u001b[0;34m= \u001b[0;36mundefined\u001b[0m\u001b[0m\u001b[0;34m\n",
            "        \u001b[0m\u001b[0;36mglobal\u001b[0m \u001b[0;36mnp.mean\u001b[0m \u001b[0;34m= <function mean at 0x7f82c819e280>\u001b[0m\u001b[0;34m\n",
            "        \u001b[0m\u001b[0;36mglobal\u001b[0m \u001b[0;36mobjective\u001b[0m \u001b[0;34m= CrossEntropyLoss()\u001b[0m\u001b[0;34m\n",
            "        \u001b[0m\u001b[0;36mglobal\u001b[0m \u001b[0;36mmodel\u001b[0m \u001b[0;34m= DamageDetection(\n",
            "  (dblock1): ConvBlock(\n",
            "    (conv1): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  )\n",
            "  (dblock2): ConvBlock(\n",
            "    (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  )\n",
            "  (dblock3): ConvBlock(\n",
            "    (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  )\n",
            "  (dblock4): ConvBlock(\n",
            "    (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  )\n",
            "  (ublock1): ConvBlock(\n",
            "    (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (up): ConvTranspose2d(512, 256, kernel_size=(2, 2), stride=(2, 2))\n",
            "  )\n",
            "  (ublock2): ConvBlock(\n",
            "    (conv1): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (up): ConvTranspose2d(256, 128, kernel_size=(2, 2), stride=(2, 2))\n",
            "  )\n",
            "  (ublock3): ConvBlock(\n",
            "    (conv1): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (up): ConvTranspose2d(128, 64, kernel_size=(2, 2), stride=(2, 2))\n",
            "  )\n",
            "  (ublock4): ConvBlock(\n",
            "    (conv1): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (up): ConvTranspose2d(64, 32, kernel_size=(2, 2), stride=(2, 2))\n",
            "  )\n",
            "  (convf1): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (convf2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (convf3): Conv2d(32, 2, kernel_size=(1, 1), stride=(1, 1))\n",
            "  (down): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            ")\u001b[0m\u001b[0;34m\n",
            "        \u001b[0m\u001b[0;36mx.cuda\u001b[0m \u001b[0;34m= \u001b[0;36mundefined\u001b[0m\u001b[0m\u001b[0;34m\n",
            "        \u001b[0m\u001b[0;36my.cuda.long.item\u001b[0m \u001b[0;34m= \u001b[0;36mundefined\u001b[0m\u001b[0m\u001b[0;34m\n",
            "        \u001b[0m\u001b[0;36mx\u001b[0m \u001b[0;34m= \u001b[0;36mundefined\u001b[0m\u001b[0m\u001b[0;34m\n",
            "        \u001b[0m\u001b[0;36my\u001b[0m \u001b[0;34m= \u001b[0;36mundefined\u001b[0m\u001b[0m\u001b[0;34m\n",
            "        \u001b[0m\u001b[0;36mglobal\u001b[0m \u001b[0;36mval_loader\u001b[0m \u001b[0;34m= \u001b[0;36mundefined\u001b[0m\u001b[0m\n",
            "\u001b[1;32m     45\u001b[0m             \u001b[0mval_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m     46\u001b[0m             \u001b[0mvalidations\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlosses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self=<torch.utils.data.dataloader._MultiProcessingDataLoaderIter object>)\u001b[0m\n",
            "\u001b[1;32m    632\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m    633\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m--> 634\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0m        \u001b[0;36mdata\u001b[0m \u001b[0;34m= \u001b[0;36mundefined\u001b[0m\u001b[0m\u001b[0;34m\n",
            "        \u001b[0m\u001b[0;36mself._next_data\u001b[0m \u001b[0;34m= <bound method _MultiProcessingDataLoaderIter._next_data of <torch.utils.data.dataloader._MultiProcessingDataLoaderIter object at 0x7f81ea6acac0>>\u001b[0m\n",
            "\u001b[1;32m    635\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m    636\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self=<torch.utils.data.dataloader._MultiProcessingDataLoaderIter object>)\u001b[0m\n",
            "\u001b[1;32m   1344\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m   1345\u001b[0m                 \u001b[0;32mdel\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_task_info\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m-> 1346\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0m        \u001b[0;36mself._process_data\u001b[0m \u001b[0;34m= <bound method _MultiProcessingDataLoaderIter._process_data of <torch.utils.data.dataloader._MultiProcessingDataLoaderIter object at 0x7f81ea6acac0>>\u001b[0m\u001b[0;34m\n",
            "        \u001b[0m\u001b[0;36mdata\u001b[0m \u001b[0;34m= <torch._utils.ExceptionWrapper object at 0x7f81e9646ca0>\u001b[0m\n",
            "\u001b[1;32m   1347\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m   1348\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_try_put_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_process_data\u001b[0;34m(self=<torch.utils.data.dataloader._MultiProcessingDataLoaderIter object>, data=<torch._utils.ExceptionWrapper object>)\u001b[0m\n",
            "\u001b[1;32m   1370\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_put_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m   1371\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mExceptionWrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m-> 1372\u001b[0;31m             \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0m        \u001b[0;36mdata.reraise\u001b[0m \u001b[0;34m= <bound method ExceptionWrapper.reraise of <torch._utils.ExceptionWrapper object at 0x7f81e9646ca0>>\u001b[0m\n",
            "\u001b[1;32m   1373\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m   1374\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/_utils.py\u001b[0m in \u001b[0;36mreraise\u001b[0;34m(self=<torch._utils.ExceptionWrapper object>)\u001b[0m\n",
            "\u001b[1;32m    642\u001b[0m             \u001b[0;31m# instantiate since we don't know how to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m    643\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m--> 644\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mexception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0m        \u001b[0;36mexception\u001b[0m \u001b[0;34m= IndexError('Caught IndexError in DataLoader worker process 0.\\nOriginal Traceback (most recent call last):\\n  File \"/usr/local/lib/python3.9/dist-packages/torch/utils/data/_utils/worker.py\", line 308, in _worker_loop\\n    data = fetcher.fetch(index)\\n  File \"/usr/local/lib/python3.9/dist-packages/torch/utils/data/_utils/fetch.py\", line 51, in fetch\\n    data = [self.dataset[idx] for idx in possibly_batched_index]\\n  File \"/usr/local/lib/python3.9/dist-packages/torch/utils/data/_utils/fetch.py\", line 51, in <listcomp>\\n    data = [self.dataset[idx] for idx in possibly_batched_index]\\n  File \"<ipython-input-12-26e8756b5acd>\", line 37, in __getitem__\\n    label = self.label_folder[index]\\n  File \"/usr/local/lib/python3.9/dist-packages/torch/utils/data/dataset.py\", line 243, in __getitem__\\n    return self.datasets[dataset_idx][sample_idx]\\nIndexError: list index out of range\\n')\u001b[0m\n",
            "\u001b[1;32m    645\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m    646\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\n",
            "\u001b[0;31mIndexError\u001b[0m: Caught IndexError in DataLoader worker process 0.\n",
            "Original Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/torch/utils/data/_utils/worker.py\", line 308, in _worker_loop\n",
            "    data = fetcher.fetch(index)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/torch/utils/data/_utils/fetch.py\", line 51, in fetch\n",
            "    data = [self.dataset[idx] for idx in possibly_batched_index]\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/torch/utils/data/_utils/fetch.py\", line 51, in <listcomp>\n",
            "    data = [self.dataset[idx] for idx in possibly_batched_index]\n",
            "  File \"<ipython-input-12-26e8756b5acd>\", line 37, in __getitem__\n",
            "    label = self.label_folder[index]\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/torch/utils/data/dataset.py\", line 243, in __getitem__\n",
            "    return self.datasets[dataset_idx][sample_idx]\n",
            "IndexError: list index out of range\n",
            "\n"
          ]
        }
      ],
      "source": [
        "def scope():\n",
        "  try:\n",
        "    #your code for calling dataset and dataloader\n",
        "    train_loader = DataLoader(train_dataset, \n",
        "                                  batch_size = 6,\n",
        "                                  num_workers = 2, \n",
        "                                  pin_memory = True,\n",
        "                                  shuffle = True)\n",
        "    val_loader = DataLoader(val_dataset, \n",
        "                            batch_size = 6,\n",
        "                            num_workers = 2,\n",
        "                            pin_memory = True,\n",
        "                            shuffle = True)\n",
        "    gc.collect()\n",
        "    print(torch.cuda.memory_allocated() / 1e9)\n",
        "    \n",
        "    val_acc = 0\n",
        "\n",
        "    # Run your training and validation loop and collect stats\n",
        "    for epoch in range(2):\n",
        "\n",
        "      loop = tqdm(total=len(train_loader), position=0, leave=False)\n",
        "\n",
        "      for batch, (x, y_truth) in enumerate(train_loader):\n",
        "        x, y_truth = x.cuda(), y_truth.cuda()\n",
        "        \n",
        "        # Call your model, figure out loss and accuracy\n",
        "        optimizer.zero_grad()\n",
        "        y_hat = model(x)\n",
        "\n",
        "        loss = objective(y_hat, y_truth.long())\n",
        "        loss.backward()\n",
        "        losses.append(loss.item())\n",
        "\n",
        "        accuracy = (torch.softmax(y_hat, 1).argmax(1) == y_truth).float().mean()\n",
        "        accuracies.append(accuracy.cpu())\n",
        "        loop.set_description('epoch{}, loss:{:.4f}, accuracy:{:.3f} val_acc:{:.3f}'.format(epoch, loss.item(), accuracy, val_acc))\n",
        "        loop.update(1)\n",
        "\n",
        "        optimizer.step()\n",
        "\n",
        "        if batch % 20 == 0:\n",
        "          with torch.no_grad():\n",
        "            val = np.mean([objective(model(x.cuda()), y.cuda().long()).item() for x, y in val_loader])\n",
        "            val_acc = np.mean([(model(x.cuda()).argmax(1) == y.cuda().long()).float().mean().item() for x, y in val_loader])\n",
        "            validations.append((len(losses), val))\n",
        "            val_accs.append((len(accuracies), val_acc))\n",
        "\n",
        "      pred_img.append(model(val_dataset[-1][0].unsqueeze(0).cuda()))\n",
        "\n",
        "      loop.close()\n",
        "\n",
        "  except:\n",
        "    __ITB__()\n",
        "    \n",
        "scope()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wu0PyJ7jqfeh"
      },
      "source": [
        "Show Accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "Q4WA6bblqevr",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 236
        },
        "outputId": "f609b47f-d30c-461d-a751-abf73a4fa7bd"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-73918b5fa057>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mvalidations\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlosses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Train\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Validation\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Steps\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: not enough values to unpack (expected 2, got 0)"
          ]
        }
      ],
      "source": [
        "a, b = zip(*validations)\n",
        "\n",
        "plt.plot(losses, label=\"Train\")\n",
        "plt.plot(a, b, label=\"Validation\")\n",
        "plt.xlabel(\"Steps\")\n",
        "plt.ylabel(\"Error\")\n",
        "plt.ylim(0, 1)\n",
        "plt.title(\"Model Error\")\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rr85nzKfqiZm"
      },
      "outputs": [],
      "source": [
        "a, b = zip(*val_accs)\n",
        "print(f\"Final Accuracy: {b[-1]}\")\n",
        "\n",
        "plt.plot(accuracies, label=\"Train\")\n",
        "plt.plot(a, b, label=\"Validation\")\n",
        "plt.xlabel(\"Steps\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.title(\"Model Accuracy\")\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pl9dJkx6qm3R"
      },
      "source": [
        "Testing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CgeNQq55qn-o"
      },
      "outputs": [],
      "source": [
        "import matplotlib.image as mpimg\n",
        "img = mpimg.imread('/content/damage_coco/test/72.jpg')\n",
        "plt.imshow(img)\n",
        "plt.title(\"Original Image\")\n",
        "print(img.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mXRLdAZbqyBx"
      },
      "outputs": [],
      "source": [
        "for i, p in enumerate(pred_img):\n",
        "  q = p.squeeze(0).argmax(0).cpu().detach().numpy()\n",
        "  plt.imshow(q, cmap=\"gray\")\n",
        "  plt.title(f\"Classification after Epoch {i}\")\n",
        "  print(np.sum(q))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(train_dataset))"
      ],
      "metadata": {
        "id": "P_LkgmPzhJgm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(len(train_dataset)):\n",
        "  q = model(train_dataset[i][0].unsqueeze(0).cuda()).squeeze(0).argmax(0).cpu().detach().numpy()\n",
        "  if np.sum(q) != 0:\n",
        "    print(i, np.sum(q))"
      ],
      "metadata": {
        "id": "M1utU0DMfuly"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}