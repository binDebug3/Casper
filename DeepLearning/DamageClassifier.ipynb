{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8GY-I6zktaPg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0553db46-2e6d-45ba-b547-b2033a2a3278"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.8/dist-packages (1.13.1+cu116)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torch) (4.5.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.8/dist-packages (0.14.1+cu116)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from torchvision) (1.22.4)\n",
            "Requirement already satisfied: torch==1.13.1 in /usr/local/lib/python3.8/dist-packages (from torchvision) (1.13.1+cu116)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from torchvision) (2.25.1)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.8/dist-packages (from torchvision) (8.4.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torchvision) (4.5.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->torchvision) (1.26.14)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->torchvision) (4.0.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->torchvision) (2022.12.7)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->torchvision) (2.10)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (4.64.1)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: google-colab in /usr/local/lib/python3.8/dist-packages (1.0.0)\n",
            "Requirement already satisfied: pandas>=1.1.0 in /usr/local/lib/python3.8/dist-packages (from google-colab) (1.3.5)\n",
            "Requirement already satisfied: ipython~=7.9.0 in /usr/local/lib/python3.8/dist-packages (from google-colab) (7.9.0)\n",
            "Requirement already satisfied: google-auth>=1.17.2 in /usr/local/lib/python3.8/dist-packages (from google-colab) (2.16.1)\n",
            "Requirement already satisfied: portpicker~=1.3.1 in /usr/local/lib/python3.8/dist-packages (from google-colab) (1.3.9)\n",
            "Requirement already satisfied: requests>=2.25.1 in /usr/local/lib/python3.8/dist-packages (from google-colab) (2.25.1)\n",
            "Requirement already satisfied: tornado~=6.1 in /usr/local/lib/python3.8/dist-packages (from google-colab) (6.2)\n",
            "Requirement already satisfied: astor~=0.8.1 in /usr/local/lib/python3.8/dist-packages (from google-colab) (0.8.1)\n",
            "Requirement already satisfied: ipykernel~=5.3.4 in /usr/local/lib/python3.8/dist-packages (from google-colab) (5.3.4)\n",
            "Requirement already satisfied: notebook~=6.3.0 in /usr/local/lib/python3.8/dist-packages (from google-colab) (6.3.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.8/dist-packages (from google-auth>=1.17.2->google-colab) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.8/dist-packages (from google-auth>=1.17.2->google-colab) (4.9)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from google-auth>=1.17.2->google-colab) (5.3.0)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.8/dist-packages (from google-auth>=1.17.2->google-colab) (1.15.0)\n",
            "Requirement already satisfied: jupyter-client in /usr/local/lib/python3.8/dist-packages (from ipykernel~=5.3.4->google-colab) (6.1.12)\n",
            "Requirement already satisfied: traitlets>=4.1.0 in /usr/local/lib/python3.8/dist-packages (from ipykernel~=5.3.4->google-colab) (5.7.1)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.8/dist-packages (from ipython~=7.9.0->google-colab) (0.7.5)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.8/dist-packages (from ipython~=7.9.0->google-colab) (57.4.0)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.8/dist-packages (from ipython~=7.9.0->google-colab) (4.4.2)\n",
            "Collecting jedi>=0.10\n",
            "  Downloading jedi-0.18.2-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m14.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pexpect in /usr/local/lib/python3.8/dist-packages (from ipython~=7.9.0->google-colab) (4.8.0)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.8/dist-packages (from ipython~=7.9.0->google-colab) (0.2.0)\n",
            "Requirement already satisfied: prompt-toolkit<2.1.0,>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from ipython~=7.9.0->google-colab) (2.0.10)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.8/dist-packages (from ipython~=7.9.0->google-colab) (2.6.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.8/dist-packages (from notebook~=6.3.0->google-colab) (3.1.2)\n",
            "Requirement already satisfied: terminado>=0.8.3 in /usr/local/lib/python3.8/dist-packages (from notebook~=6.3.0->google-colab) (0.13.3)\n",
            "Requirement already satisfied: nbformat in /usr/local/lib/python3.8/dist-packages (from notebook~=6.3.0->google-colab) (5.7.3)\n",
            "Requirement already satisfied: nbconvert in /usr/local/lib/python3.8/dist-packages (from notebook~=6.3.0->google-colab) (6.5.4)\n",
            "Requirement already satisfied: Send2Trash>=1.5.0 in /usr/local/lib/python3.8/dist-packages (from notebook~=6.3.0->google-colab) (1.8.0)\n",
            "Requirement already satisfied: jupyter-core>=4.6.1 in /usr/local/lib/python3.8/dist-packages (from notebook~=6.3.0->google-colab) (5.2.0)\n",
            "Requirement already satisfied: prometheus-client in /usr/local/lib/python3.8/dist-packages (from notebook~=6.3.0->google-colab) (0.16.0)\n",
            "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.8/dist-packages (from notebook~=6.3.0->google-colab) (0.2.0)\n",
            "Requirement already satisfied: argon2-cffi in /usr/local/lib/python3.8/dist-packages (from notebook~=6.3.0->google-colab) (21.3.0)\n",
            "Requirement already satisfied: pyzmq>=17 in /usr/local/lib/python3.8/dist-packages (from notebook~=6.3.0->google-colab) (23.2.1)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas>=1.1.0->google-colab) (2022.7.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.8/dist-packages (from pandas>=1.1.0->google-colab) (2.8.2)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.8/dist-packages (from pandas>=1.1.0->google-colab) (1.22.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests>=2.25.1->google-colab) (2.10)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests>=2.25.1->google-colab) (4.0.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests>=2.25.1->google-colab) (2022.12.7)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests>=2.25.1->google-colab) (1.26.14)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /usr/local/lib/python3.8/dist-packages (from jedi>=0.10->ipython~=7.9.0->google-colab) (0.8.3)\n",
            "Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.8/dist-packages (from jupyter-core>=4.6.1->notebook~=6.3.0->google-colab) (3.0.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.8/dist-packages (from prompt-toolkit<2.1.0,>=2.0.0->ipython~=7.9.0->google-colab) (0.2.6)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.8/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=1.17.2->google-colab) (0.4.8)\n",
            "Requirement already satisfied: ptyprocess in /usr/local/lib/python3.8/dist-packages (from terminado>=0.8.3->notebook~=6.3.0->google-colab) (0.7.0)\n",
            "Requirement already satisfied: argon2-cffi-bindings in /usr/local/lib/python3.8/dist-packages (from argon2-cffi->notebook~=6.3.0->google-colab) (21.2.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.8/dist-packages (from jinja2->notebook~=6.3.0->google-colab) (2.1.2)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.8/dist-packages (from nbconvert->notebook~=6.3.0->google-colab) (0.7.1)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.8/dist-packages (from nbconvert->notebook~=6.3.0->google-colab) (6.0.0)\n",
            "Requirement already satisfied: tinycss2 in /usr/local/lib/python3.8/dist-packages (from nbconvert->notebook~=6.3.0->google-colab) (1.2.1)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.8/dist-packages (from nbconvert->notebook~=6.3.0->google-colab) (4.6.3)\n",
            "Requirement already satisfied: jupyterlab-pygments in /usr/local/lib/python3.8/dist-packages (from nbconvert->notebook~=6.3.0->google-colab) (0.2.2)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.8/dist-packages (from nbconvert->notebook~=6.3.0->google-colab) (1.5.0)\n",
            "Requirement already satisfied: entrypoints>=0.2.2 in /usr/local/lib/python3.8/dist-packages (from nbconvert->notebook~=6.3.0->google-colab) (0.4)\n",
            "Requirement already satisfied: nbclient>=0.5.0 in /usr/local/lib/python3.8/dist-packages (from nbconvert->notebook~=6.3.0->google-colab) (0.7.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from nbconvert->notebook~=6.3.0->google-colab) (23.0)\n",
            "Requirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.8/dist-packages (from nbconvert->notebook~=6.3.0->google-colab) (0.8.4)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.8/dist-packages (from nbconvert->notebook~=6.3.0->google-colab) (4.9.2)\n",
            "Requirement already satisfied: fastjsonschema in /usr/local/lib/python3.8/dist-packages (from nbformat->notebook~=6.3.0->google-colab) (2.16.3)\n",
            "Requirement already satisfied: jsonschema>=2.6 in /usr/local/lib/python3.8/dist-packages (from nbformat->notebook~=6.3.0->google-colab) (4.3.3)\n",
            "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /usr/local/lib/python3.8/dist-packages (from jsonschema>=2.6->nbformat->notebook~=6.3.0->google-colab) (0.19.3)\n",
            "Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.8/dist-packages (from jsonschema>=2.6->nbformat->notebook~=6.3.0->google-colab) (22.2.0)\n",
            "Requirement already satisfied: importlib-resources>=1.4.0 in /usr/local/lib/python3.8/dist-packages (from jsonschema>=2.6->nbformat->notebook~=6.3.0->google-colab) (5.12.0)\n",
            "Requirement already satisfied: cffi>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from argon2-cffi-bindings->argon2-cffi->notebook~=6.3.0->google-colab) (1.15.1)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.8/dist-packages (from bleach->nbconvert->notebook~=6.3.0->google-colab) (0.5.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.8/dist-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi->notebook~=6.3.0->google-colab) (2.21)\n",
            "Requirement already satisfied: zipp>=3.1.0 in /usr/local/lib/python3.8/dist-packages (from importlib-resources>=1.4.0->jsonschema>=2.6->nbformat->notebook~=6.3.0->google-colab) (3.15.0)\n",
            "Installing collected packages: jedi\n",
            "Successfully installed jedi-0.18.2\n"
          ]
        }
      ],
      "source": [
        "# import and install packages\n",
        "\n",
        "!pip3 install torch\n",
        "!pip3 install torchvision\n",
        "!pip3 install tqdm\n",
        "!pip install google-colab\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from torchvision import transforms, utils, datasets\n",
        "from tqdm import tqdm\n",
        "from torch.nn.parameter import Parameter\n",
        "import pdb\n",
        "import torchvision\n",
        "import os\n",
        "import gzip\n",
        "import tarfile\n",
        "import gc\n",
        "from google.colab import files\n",
        "from google.colab import drive\n",
        "import json\n",
        "from PIL import Image, ImageDraw\n",
        "from IPython.core.ultratb import AutoFormattedTB\n",
        "__ITB__ = AutoFormattedTB(mode = 'Verbose',color_scheme='LightBg', tb_offset = 1)\n",
        "\n",
        "# assert torch.cuda.is_available(), \"You need to request a GPU from Runtime > Change Runtime\""
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load Images"
      ],
      "metadata": {
        "id": "hfeTnKCNH4iM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "drive.mount('/content/drive')\n",
        "path_coco = \"/content/damage_coco\"\n",
        "path_robo = \"/content/damage_roboflow\"\n",
        "\n",
        "if not os.path.exists(path_coco):\n",
        "    os.makedirs(path_coco)\n",
        "if not os.path.exists(path_robo):\n",
        "    os.makedirs(path_robo)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OjgZO1pOY8ll",
        "outputId": "191f0942-af47-4831-871e-96b764b0c3fb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip /content/drive/MyDrive/College/3.\\ Junior/Winter\\ Semester/CS\\ 474/Final\\ DL/Car_Data/damage_coco.zip -d /content/damage_coco\n",
        "# !unzip /content/gdrive/My\\ Drive/College/3.\\ Junior/Winter\\ Semester/CS\\ 474/Final\\ DL/Car_Data/damage_roboflow.zip -d /content/damage_roboflow\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xy4aiw2BY-kI",
        "outputId": "411d6f7c-4e80-4054-f47f-89a3152b335e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  /content/drive/MyDrive/College/3. Junior/Winter Semester/CS 474/Final DL/Car_Data/damage_coco.zip\n",
            "  inflating: /content/damage_coco/img/1.jpg  \n",
            "  inflating: /content/damage_coco/img/10.jpg  \n",
            "  inflating: /content/damage_coco/img/13.jpg  \n",
            "  inflating: /content/damage_coco/img/14.jpg  \n",
            "  inflating: /content/damage_coco/img/15.jpg  \n",
            "  inflating: /content/damage_coco/img/16.jpg  \n",
            "  inflating: /content/damage_coco/img/17.jpg  \n",
            "  inflating: /content/damage_coco/img/18.jpg  \n",
            "  inflating: /content/damage_coco/img/19.jpg  \n",
            "  inflating: /content/damage_coco/img/2.jpg  \n",
            "  inflating: /content/damage_coco/img/20.jpg  \n",
            "  inflating: /content/damage_coco/img/21.jpg  \n",
            "  inflating: /content/damage_coco/img/22.jpg  \n",
            "  inflating: /content/damage_coco/img/23.jpg  \n",
            "  inflating: /content/damage_coco/img/24.jpg  \n",
            "  inflating: /content/damage_coco/img/25.jpg  \n",
            "  inflating: /content/damage_coco/img/26.jpg  \n",
            "  inflating: /content/damage_coco/img/27.jpg  \n",
            "  inflating: /content/damage_coco/img/29.jpg  \n",
            "  inflating: /content/damage_coco/img/3.jpg  \n",
            "  inflating: /content/damage_coco/img/30.jpg  \n",
            "  inflating: /content/damage_coco/img/31.jpg  \n",
            "  inflating: /content/damage_coco/img/32.jpg  \n",
            "  inflating: /content/damage_coco/img/33.jpg  \n",
            "  inflating: /content/damage_coco/img/34.jpg  \n",
            "  inflating: /content/damage_coco/img/36.jpg  \n",
            "  inflating: /content/damage_coco/img/37.jpg  \n",
            "  inflating: /content/damage_coco/img/38.jpg  \n",
            "  inflating: /content/damage_coco/img/39.jpg  \n",
            "  inflating: /content/damage_coco/img/4.jpg  \n",
            "  inflating: /content/damage_coco/img/40.jpg  \n",
            "  inflating: /content/damage_coco/img/41.jpg  \n",
            "  inflating: /content/damage_coco/img/42.jpg  \n",
            "  inflating: /content/damage_coco/img/43.jpg  \n",
            "  inflating: /content/damage_coco/img/44.jpg  \n",
            "  inflating: /content/damage_coco/img/46.jpg  \n",
            "  inflating: /content/damage_coco/img/47.jpg  \n",
            "  inflating: /content/damage_coco/img/48.jpg  \n",
            "  inflating: /content/damage_coco/img/49.jpg  \n",
            "  inflating: /content/damage_coco/img/5.jpg  \n",
            "  inflating: /content/damage_coco/img/50.jpg  \n",
            "  inflating: /content/damage_coco/img/51.jpg  \n",
            "  inflating: /content/damage_coco/img/52.jpg  \n",
            "  inflating: /content/damage_coco/img/53.jpg  \n",
            "  inflating: /content/damage_coco/img/54.jpg  \n",
            "  inflating: /content/damage_coco/img/55.jpg  \n",
            "  inflating: /content/damage_coco/img/56.jpg  \n",
            "  inflating: /content/damage_coco/img/57.jpg  \n",
            "  inflating: /content/damage_coco/img/58.jpg  \n",
            "  inflating: /content/damage_coco/img/59.jpg  \n",
            "  inflating: /content/damage_coco/img/6.jpg  \n",
            "  inflating: /content/damage_coco/img/61.jpg  \n",
            "  inflating: /content/damage_coco/img/62.jpg  \n",
            "  inflating: /content/damage_coco/img/63.jpg  \n",
            "  inflating: /content/damage_coco/img/64.jpg  \n",
            "  inflating: /content/damage_coco/img/68.jpg  \n",
            "  inflating: /content/damage_coco/img/69.jpg  \n",
            "  inflating: /content/damage_coco/img/7.jpg  \n",
            "  inflating: /content/damage_coco/img/70.jpg  \n",
            "  inflating: /content/damage_coco/img/71.jpg  \n",
            "  inflating: /content/damage_coco/img/73.jpg  \n",
            "  inflating: /content/damage_coco/img/74.jpg  \n",
            "  inflating: /content/damage_coco/img/75.jpg  \n",
            "  inflating: /content/damage_coco/img/76.jpg  \n",
            "  inflating: /content/damage_coco/img/77.jpg  \n",
            "  inflating: /content/damage_coco/img/78.jpg  \n",
            "  inflating: /content/damage_coco/img/79.jpg  \n",
            "  inflating: /content/damage_coco/img/8.jpg  \n",
            "  inflating: /content/damage_coco/img/80.jpg  \n",
            "  inflating: /content/damage_coco/img/9.jpg  \n",
            "  inflating: /content/damage_coco/test/11.jpg  \n",
            "  inflating: /content/damage_coco/test/12.jpg  \n",
            "  inflating: /content/damage_coco/test/28.jpg  \n",
            "  inflating: /content/damage_coco/test/45.jpg  \n",
            "  inflating: /content/damage_coco/test/60.jpg  \n",
            "  inflating: /content/damage_coco/test/66.jpg  \n",
            "  inflating: /content/damage_coco/test/67.jpg  \n",
            "  inflating: /content/damage_coco/test/72.jpg  \n",
            "  inflating: /content/damage_coco/train/10.jpg  \n",
            "  inflating: /content/damage_coco/train/13.jpg  \n",
            "  inflating: /content/damage_coco/train/14.jpg  \n",
            "  inflating: /content/damage_coco/train/15.jpg  \n",
            "  inflating: /content/damage_coco/train/16.jpg  \n",
            "  inflating: /content/damage_coco/train/17.jpg  \n",
            "  inflating: /content/damage_coco/train/18.jpg  \n",
            "  inflating: /content/damage_coco/train/19.jpg  \n",
            "  inflating: /content/damage_coco/train/2.jpg  \n",
            "  inflating: /content/damage_coco/train/20.jpg  \n",
            "  inflating: /content/damage_coco/train/21.jpg  \n",
            "  inflating: /content/damage_coco/train/23.jpg  \n",
            "  inflating: /content/damage_coco/train/25.jpg  \n",
            "  inflating: /content/damage_coco/train/26.jpg  \n",
            "  inflating: /content/damage_coco/train/27.jpg  \n",
            "  inflating: /content/damage_coco/train/29.jpg  \n",
            "  inflating: /content/damage_coco/train/30.jpg  \n",
            "  inflating: /content/damage_coco/train/31.jpg  \n",
            "  inflating: /content/damage_coco/train/33.jpg  \n",
            "  inflating: /content/damage_coco/train/34.jpg  \n",
            "  inflating: /content/damage_coco/train/36.jpg  \n",
            "  inflating: /content/damage_coco/train/37.jpg  \n",
            "  inflating: /content/damage_coco/train/38.jpg  \n",
            "  inflating: /content/damage_coco/train/39.jpg  \n",
            "  inflating: /content/damage_coco/train/4.jpg  \n",
            "  inflating: /content/damage_coco/train/40.jpg  \n",
            "  inflating: /content/damage_coco/train/41.jpg  \n",
            "  inflating: /content/damage_coco/train/43.jpg  \n",
            "  inflating: /content/damage_coco/train/44.jpg  \n",
            "  inflating: /content/damage_coco/train/46.jpg  \n",
            "  inflating: /content/damage_coco/train/47.jpg  \n",
            "  inflating: /content/damage_coco/train/48.jpg  \n",
            "  inflating: /content/damage_coco/train/49.jpg  \n",
            "  inflating: /content/damage_coco/train/5.jpg  \n",
            "  inflating: /content/damage_coco/train/50.jpg  \n",
            "  inflating: /content/damage_coco/train/51.jpg  \n",
            "  inflating: /content/damage_coco/train/52.jpg  \n",
            "  inflating: /content/damage_coco/train/53.jpg  \n",
            "  inflating: /content/damage_coco/train/54.jpg  \n",
            "  inflating: /content/damage_coco/train/55.jpg  \n",
            "  inflating: /content/damage_coco/train/56.jpg  \n",
            "  inflating: /content/damage_coco/train/57.jpg  \n",
            "  inflating: /content/damage_coco/train/58.jpg  \n",
            "  inflating: /content/damage_coco/train/59.jpg  \n",
            "  inflating: /content/damage_coco/train/6.jpg  \n",
            "  inflating: /content/damage_coco/train/61.jpg  \n",
            "  inflating: /content/damage_coco/train/63.jpg  \n",
            "  inflating: /content/damage_coco/train/64.jpg  \n",
            "  inflating: /content/damage_coco/train/68.jpg  \n",
            "  inflating: /content/damage_coco/train/69.jpg  \n",
            "  inflating: /content/damage_coco/train/7.jpg  \n",
            "  inflating: /content/damage_coco/train/70.jpg  \n",
            "  inflating: /content/damage_coco/train/71.jpg  \n",
            "  inflating: /content/damage_coco/train/73.jpg  \n",
            "  inflating: /content/damage_coco/train/75.jpg  \n",
            "  inflating: /content/damage_coco/train/76.jpg  \n",
            "  inflating: /content/damage_coco/train/77.jpg  \n",
            "  inflating: /content/damage_coco/train/79.jpg  \n",
            "  inflating: /content/damage_coco/train/80.jpg  \n",
            "  inflating: /content/damage_coco/train/COCO_mul_train_annos.json  \n",
            "  inflating: /content/damage_coco/train/COCO_train_annos.json  \n",
            "  inflating: /content/damage_coco/val/1.jpg  \n",
            "  inflating: /content/damage_coco/val/22.jpg  \n",
            "  inflating: /content/damage_coco/val/24.jpg  \n",
            "  inflating: /content/damage_coco/val/3.jpg  \n",
            "  inflating: /content/damage_coco/val/32.jpg  \n",
            "  inflating: /content/damage_coco/val/42.jpg  \n",
            "  inflating: /content/damage_coco/val/62.jpg  \n",
            "  inflating: /content/damage_coco/val/74.jpg  \n",
            "  inflating: /content/damage_coco/val/78.jpg  \n",
            "  inflating: /content/damage_coco/val/8.jpg  \n",
            "  inflating: /content/damage_coco/val/9.jpg  \n",
            "  inflating: /content/damage_coco/val/COCO_mul_val_annos.json  \n",
            "  inflating: /content/damage_coco/val/COCO_val_annos.json  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "path_coco = \"/content/damage_coco/train/0\"\n",
        "\n",
        "if not os.path.exists(path_coco):\n",
        "    os.makedirs(path_coco)"
      ],
      "metadata": {
        "id": "2LGhlA3ffv2W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mv /content/damage_coco/train/*.jpg /content/damage_coco/train/0"
      ],
      "metadata": {
        "id": "9tCXYxntf6sE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if not os.path.exists(\"/content/damage_coco/masks\"):\n",
        "    os.makedirs(\"/content/damage_coco/masks\")\n",
        "\n",
        "# Load the JSON data\n",
        "with open('/content/damage_coco/train/COCO_train_annos.json') as f:\n",
        "    data = json.load(f)\n",
        "\n",
        "# Get the image size\n",
        "width, height = data['images'][0]['width'], data['images'][0]['height']\n",
        "# Create an empty mask\n",
        "mask = np.zeros((height, width), dtype=np.uint8)\n",
        "\n",
        "last_image = 0\n",
        "damage_count = 0\n",
        "for annotation in data['annotations']:\n",
        "  if last_image == annotation['image_id']:\n",
        "    damage_count += 1\n",
        "  else:\n",
        "    last_image = annotation['image_id']\n",
        "    damage_count = 0\n",
        "  box = annotation['bbox']\n",
        "  mask[box[0]:box[0]+box[2]+1, box[1]:box[1]+box[3]+1] = True\n",
        "  name = '/content/damage_coco/masks/mask'+ \\\n",
        "          str(annotation['image_id'])+'_'+str(damage_count)+'.png'\n",
        "  # np.save(name, mask)\n",
        "\n",
        "  # Convert the array to an image\n",
        "  img = Image.fromarray(mask*255)\n",
        "  # Save the image as a PNG file\n",
        "  img.save(name)\n",
        "\n",
        "\n",
        "# # Draw polygons on the mask for each damaged area\n",
        "# for annotation in data['annotations']:\n",
        "#     segmentation = annotation['segmentation'][0]\n",
        "#     polygon = [(segmentation[i], segmentation[i+1]) for i in range(0, len(segmentation), 2)]\n",
        "#     ImageDraw.Draw(Image.fromarray(mask)).polygon(polygon, outline=1, fill=1)\n",
        "#     mask = np.array(mask)\n",
        "#     break\n",
        "\n",
        "# # Save the mask as an image\n",
        "# Image.fromarray(mask*255).save('mask.png')"
      ],
      "metadata": {
        "id": "gYqIbPMO8TzI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DamagedDataset(Dataset):\n",
        "  def __init__(self, root, download=True, size=512, train=True):\n",
        "    postfix = 'train' if train else 'val'\n",
        "    self.dataset_folder = torchvision.datasets.ImageFolder(os.path.join(root, postfix), \n",
        "                                                           transform = transforms.Compose([\n",
        "                                                               transforms.Resize(size),\n",
        "                                                               transforms.ToTensor()\n",
        "                                                               ]))\n",
        "    self.label_folder = torchvision.datasets.ImageFolder(os.path.join(root), \n",
        "                                                         transform = transforms.Compose([\n",
        "                                                             transforms.Resize(size),\n",
        "                                                             transforms.ToTensor()\n",
        "                                                             ]))\n",
        "  def __getitem__(self,index):\n",
        "    img = self.dataset_folder[index]\n",
        "    label = self.label_folder[index]\n",
        "    return img[0],label[0][0]\n",
        "  \n",
        "  def __len__(self):\n",
        "    return len(self.dataset_folder)"
      ],
      "metadata": {
        "id": "_zjUpWtZHxwU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Neural Net"
      ],
      "metadata": {
        "id": "fbpCZsjvpzoB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class DamageDetection(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(DamageDetection, self).__init__()\n",
        "\n",
        "    # input top left\n",
        "    self.conv1 = nn.Conv2d(3,64,kernel_size=3, stride=1, padding=1)\n",
        "    self.conv1b = nn.Conv2d(64,64,kernel_size=3, stride=1, padding=1)\n",
        "    self.max1 = nn.MaxPool2d(kernel_size=2)\n",
        "\n",
        "    self.conv2 = nn.Conv2d(64,128,kernel_size=3, stride=1, padding=1)\n",
        "    self.conv2b = nn.Conv2d(128,128,kernel_size=3, stride=1, padding=1)\n",
        "    self.max2 = nn.MaxPool2d(kernel_size=2)\n",
        "\n",
        "    self.conv3 = nn.Conv2d(128,256,kernel_size=3, stride=1, padding=1)\n",
        "    self.conv3b = nn.Conv2d(256,256,kernel_size=3, stride=1, padding=1)\n",
        "    self.max3 = nn.MaxPool2d(kernel_size=2)\n",
        "\n",
        "    self.conv4 = nn.Conv2d(256,512,kernel_size=3, stride=1, padding=1)\n",
        "    self.conv4b = nn.Conv2d(512,512,kernel_size=3, stride=1, padding=1)\n",
        "    self.max4 = nn.MaxPool2d(kernel_size=2)\n",
        "    \n",
        "    # bottom\n",
        "    self.conv5 = nn.Conv2d(512,1024,kernel_size=3, stride=1, padding=1)\n",
        "    self.conv5b = nn.Conv2d(1024,1024,kernel_size=3, stride=1, padding=1)\n",
        "    self.tran5 = nn.ConvTranspose2d(1024, 512, kernel_size=2, stride=2)\n",
        "    # bottom\n",
        "    \n",
        "    self.conv6 = nn.Conv2d(1024,512,kernel_size=3, stride=1, padding=1)\n",
        "    self.conv6b = nn.Conv2d(512,512,kernel_size=3, stride=1, padding=1)\n",
        "    self.tran6 = nn.ConvTranspose2d(512, 256, kernel_size=2, stride=2)\n",
        "\n",
        "    self.conv7 = nn.Conv2d(512,256,kernel_size=3, stride=1, padding=1)\n",
        "    self.conv7b = nn.Conv2d(256,256,kernel_size=3, stride=1, padding=1)\n",
        "    self.tran7 = nn.ConvTranspose2d(256, 128, kernel_size=2, stride=2)\n",
        "\n",
        "    self.conv8 = nn.Conv2d(256,128,kernel_size=3, stride=1, padding=1)\n",
        "    self.conv8b = nn.Conv2d(128,128,kernel_size=3, stride=1, padding=1)\n",
        "    self.tran8 = nn.ConvTranspose2d(128, 64, kernel_size=2, stride=2)\n",
        "\n",
        "    self.conv9 = nn.Conv2d(128,64,kernel_size=3, stride=1, padding=1)\n",
        "    self.conv9b = nn.Conv2d(64,64,kernel_size=3, stride=1, padding=1)\n",
        "    # output top right\n",
        "    self.conv10 = nn.Conv2d(64,2,kernel_size=1, stride=1, padding=0)\n",
        "\n",
        "\n",
        "  def forward(self, input):\n",
        "    # input top left\n",
        "    convOut1a = self.conv1(input)\n",
        "    relOut1a = F.relu(convOut1a)\n",
        "    convOut1 = self.conv1b(relOut1a)\n",
        "    relOut1 = F.relu(convOut1)     # concat with tranOut8\n",
        "    maxOut1 = self.max1(relOut1)\n",
        "\n",
        "    convOut2a = self.conv2(maxOut1)\n",
        "    relOut2a = F.relu(convOut2a)\n",
        "    convOut2 = self.conv2b(relOut2a)\n",
        "    relOut2 = F.relu(convOut2)     # concat with tranOut7\n",
        "    maxOut2 = self.max2(relOut2)\n",
        "\n",
        "    convOut3a = self.conv3(maxOut2)\n",
        "    relOut3a = F.relu(convOut3a)\n",
        "    convOut3 = self.conv3b(relOut3a)\n",
        "    relOut3 = F.relu(convOut3)     # concat with tranOut6\n",
        "    maxOut3 = self.max3(relOut3)\n",
        "\n",
        "    convOut4a = self.conv4(maxOut3)\n",
        "    relOut4a = F.relu(convOut4a)\n",
        "    convOut4 = self.conv4b(relOut4a)\n",
        "    relOut4 = F.relu(convOut4)     # concat with tranOut5\n",
        "    maxOut4 = self.max4(relOut4)\n",
        "\n",
        "    # bottom\n",
        "    convOut5a = self.conv5(maxOut4)\n",
        "    relOut5a = F.relu(convOut5a)\n",
        "    convOut5 = self.conv5b(relOut5a)\n",
        "    relOut5 = F.relu(convOut5)\n",
        "    tranOut5 = self.tran5(relOut5)\n",
        "    # bottom\n",
        "\n",
        "    concat6 = torch.cat((relOut4, tranOut5), dim=1)\n",
        "    convOut6a = self.conv6(concat6)\n",
        "    relOut6a = F.relu(convOut6a)\n",
        "    convOut6 = self.conv6b(relOut6a)\n",
        "    relOut6 = F.relu(convOut6)\n",
        "    tranOut6 = self.tran6(relOut6)\n",
        "\n",
        "    concat7 = torch.cat((relOut3, tranOut6), dim=1)\n",
        "    convOut7a = self.conv7(concat7)\n",
        "    relOut7a = F.relu(convOut7a)\n",
        "    convOut7 = self.conv7b(relOut7a)\n",
        "    relOut7 = F.relu(convOut7)\n",
        "    tranOut7 = self.tran7(relOut7)\n",
        "\n",
        "    concat8 = torch.cat((relOut2, tranOut7), dim=1)\n",
        "    convOut8a = self.conv8(concat8)\n",
        "    relOut8a = F.relu(convOut8a)\n",
        "    convOut8 = self.conv8b(relOut8a)\n",
        "    relOut8 = F.relu(convOut8)\n",
        "    tranOut8 = self.tran8(relOut8)\n",
        "\n",
        "    concat9 = torch.cat((relOut1, tranOut8), dim=1)\n",
        "    convOut9a = self.conv9(concat9)\n",
        "    relOut9a = F.relu(convOut9a)\n",
        "    convOut9 = self.conv9b(relOut9a)\n",
        "    relOut9 = F.relu(convOut9)\n",
        "\n",
        "    convOut10 = self.conv10(relOut9)\n",
        "    relOut10 = F.relu(convOut10)\n",
        "\n",
        "    return relOut10"
      ],
      "metadata": {
        "id": "5ZM4V6VKpxKA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Initialize Classifier"
      ],
      "metadata": {
        "id": "iH_B7K3mIcrI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create datasets, dataloaders and neural network"
      ],
      "metadata": {
        "id": "C0kNY6BvImG9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO load masks so that they can load properly with the DamagedDataset class\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Initialize Datasets\n",
        "train_dataset = DamagedDataset('/content/damage_coco', train=True)\n",
        "val_dataset = DamagedDataset('/content/damage_coco/masks', train=False)\n",
        "\n",
        "# Initialize Model\n",
        "model = DamageDetection()\n",
        "model = model.cuda()\n",
        " # Initialize Objective and Optimizer and other parameters\n",
        "objective = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=1e-4)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 381
        },
        "id": "BQCBsgD5ImRT",
        "outputId": "a7126fa5-7be5-4ca8-a880-d7fa17bf2a9b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-62-8c308300cf1f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Initialize Datasets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mtrain_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDamagedDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/damage_coco'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mval_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDamagedDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/damage_coco/masks'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Initialize Model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-61-ba49c3a27280>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, root, download, size, train)\u001b[0m\n\u001b[1;32m      2\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mroot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdownload\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m512\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mpostfix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'train'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtrain\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m'val'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     self.dataset_folder = torchvision.datasets.ImageFolder(os.path.join(root, postfix), \n\u001b[0m\u001b[1;32m      5\u001b[0m                                                            transform = transforms.Compose([\n\u001b[1;32m      6\u001b[0m                                                                \u001b[0mtransforms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mResize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torchvision/datasets/folder.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, root, transform, target_transform, loader, is_valid_file)\u001b[0m\n\u001b[1;32m    307\u001b[0m         \u001b[0mis_valid_file\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mCallable\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    308\u001b[0m     ):\n\u001b[0;32m--> 309\u001b[0;31m         super().__init__(\n\u001b[0m\u001b[1;32m    310\u001b[0m             \u001b[0mroot\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    311\u001b[0m             \u001b[0mloader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torchvision/datasets/folder.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, root, loader, extensions, transform, target_transform, is_valid_file)\u001b[0m\n\u001b[1;32m    142\u001b[0m     ) -> None:\n\u001b[1;32m    143\u001b[0m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_transform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtarget_transform\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 144\u001b[0;31m         \u001b[0mclasses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_to_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind_classes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    145\u001b[0m         \u001b[0msamples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_to_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mextensions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_valid_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torchvision/datasets/folder.py\u001b[0m in \u001b[0;36mfind_classes\u001b[0;34m(self, directory)\u001b[0m\n\u001b[1;32m    216\u001b[0m             \u001b[0;34m(\u001b[0m\u001b[0mTuple\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mList\u001b[0m \u001b[0mof\u001b[0m \u001b[0mall\u001b[0m \u001b[0mclasses\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mdictionary\u001b[0m \u001b[0mmapping\u001b[0m \u001b[0meach\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mto\u001b[0m \u001b[0man\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    217\u001b[0m         \"\"\"\n\u001b[0;32m--> 218\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfind_classes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTuple\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torchvision/datasets/folder.py\u001b[0m in \u001b[0;36mfind_classes\u001b[0;34m(directory)\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0mSee\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;32mclass\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mDatasetFolder\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mdetails\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m     \"\"\"\n\u001b[0;32m---> 40\u001b[0;31m     \u001b[0mclasses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mentry\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mentry\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscandir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mentry\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_dir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mclasses\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mFileNotFoundError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Couldn't find any class folder in {directory}.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/damage_coco/masks/val'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "losses = []\n",
        "accuracies = []\n",
        "validations = []\n",
        "val_accs = []\n",
        "pre_img = []"
      ],
      "metadata": {
        "id": "12xZPcG7qJyM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train"
      ],
      "metadata": {
        "id": "daoFJttlqLop"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def scope():\n",
        "  try:\n",
        "    #your code for calling dataset and dataloader\n",
        "    train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True, pin_memory=True, num_workers=2)\n",
        "    val_loader = DataLoader(val_dataset, batch_size=8, pin_memory=True, num_workers=2)\n",
        "    gc.collect()\n",
        "    print(torch.cuda.memory_allocated() / 1e9)\n",
        "    \n",
        "    val_acc = 0\n",
        "\n",
        "    # Run your training and validation loop and collect stats\n",
        "    for epoch in range(1):\n",
        "\n",
        "      loop = tqdm(total=len(train_loader), position=0, leave=False)\n",
        "\n",
        "      for batch, (x, y_truth) in enumerate(train_loader):\n",
        "        x, y_truth = x.cuda(), y_truth.cuda()\n",
        "        \n",
        "        # Call your model, figure out loss and accuracy\n",
        "        optimizer.zero_grad()\n",
        "        y_hat = model(x)\n",
        "\n",
        "        loss = objective(y_hat, y_truth.long())\n",
        "        loss.backward()\n",
        "        losses.append(loss.item())\n",
        "\n",
        "        accuracy = (torch.softmax(y_hat, 1).argmax(1) == y_truth).float().mean()\n",
        "        accuracies.append(accuracy.cpu())\n",
        "        loop.set_description('epoch{}, loss:{:.4f}, accuracy:{:.3f} val_acc:{:.3f}'.format(epoch, loss.item(), accuracy, val_acc))\n",
        "        loop.update(1)\n",
        "\n",
        "        optimizer.step()\n",
        "\n",
        "        if batch % 20 == 0:\n",
        "          val = np.mean([objective(model(x.cuda()), y.cuda().long()).item() for x, y in val_loader])\n",
        "          val_acc = np.mean([(model(x.cuda()).argmax(1) == y.cuda().long()).float().mean().item() for x, y in val_loader])\n",
        "          validations.append((len(losses), val))\n",
        "          val_accs.append((len(accuracies), val_acc))\n",
        "\n",
        "      pred_img.append(model(val_dataset[172][0].unsqueeze(0).cuda()))\n",
        "\n",
        "      loop.close()\n",
        "\n",
        "  except:\n",
        "    __ITB__()\n",
        "    \n",
        "scope()"
      ],
      "metadata": {
        "id": "64Iv-WTkqMhc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Show Accuracy"
      ],
      "metadata": {
        "id": "wu0PyJ7jqfeh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "a, b = zip(*validations)\n",
        "\n",
        "plt.plot(losses, label=\"Train\")\n",
        "plt.plot(a, b, label=\"Validation\")\n",
        "plt.xlabel(\"Steps\")\n",
        "plt.ylabel(\"Error\")\n",
        "plt.ylim(0, 1)\n",
        "plt.title(\"Model Error\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Q4WA6bblqevr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a, b = zip(*val_accs)\n",
        "print(f\"Final Accuracy: {b[-1]}\")\n",
        "\n",
        "plt.plot(accuracies, label=\"Train\")\n",
        "plt.plot(a, b, label=\"Validation\")\n",
        "plt.xlabel(\"Steps\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.title(\"Model Accuracy\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "rr85nzKfqiZm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Testing"
      ],
      "metadata": {
        "id": "pl9dJkx6qm3R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.image as mpimg\n",
        "plt.imshow(mpimg.imread('Training_Data/damage/damage_coco/test/0/1.jpg'))\n",
        "plt.title(\"Original Image\")"
      ],
      "metadata": {
        "id": "CgeNQq55qn-o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i, p in enumerate(pred_img):\n",
        "  q = p.squeeze(0).argmax(0).cpu().detach().numpy()\n",
        "  plt.imshow(q, cmap=\"gray\")\n",
        "  plt.title(f\"Classification after Epoch {i}\")"
      ],
      "metadata": {
        "id": "mXRLdAZbqyBx"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}