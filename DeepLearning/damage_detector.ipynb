{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2022-01-02T07:42:56.345704Z",
     "iopub.status.busy": "2022-01-02T07:42:56.344866Z",
     "iopub.status.idle": "2022-01-02T07:42:56.374397Z",
     "shell.execute_reply": "2022-01-02T07:42:56.373617Z",
     "shell.execute_reply.started": "2022-01-02T07:42:56.345542Z"
    }
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "# for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "#     for filename in filenames:\n",
    "#         print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting roboflow\n",
      "  Downloading roboflow-0.2.32-py3-none-any.whl (50 kB)\n",
      "Requirement already satisfied: six in c:\\users\\dalli\\anaconda3\\lib\\site-packages (from roboflow) (1.16.0)\n",
      "Requirement already satisfied: Pillow>=7.1.2 in c:\\users\\dalli\\anaconda3\\lib\\site-packages (from roboflow) (8.4.0)\n",
      "Requirement already satisfied: certifi==2022.12.7 in c:\\users\\dalli\\anaconda3\\lib\\site-packages (from roboflow) (2022.12.7)\n",
      "Collecting idna==2.10\n",
      "  Downloading idna-2.10-py2.py3-none-any.whl (58 kB)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\dalli\\anaconda3\\lib\\site-packages (from roboflow) (1.3.1)\n",
      "Requirement already satisfied: urllib3>=1.26.6 in c:\\users\\dalli\\anaconda3\\lib\\site-packages (from roboflow) (1.26.7)\n",
      "Requirement already satisfied: tqdm>=4.41.0 in c:\\users\\dalli\\anaconda3\\lib\\site-packages (from roboflow) (4.62.3)\n",
      "Requirement already satisfied: chardet==4.0.0 in c:\\users\\dalli\\anaconda3\\lib\\site-packages (from roboflow) (4.0.0)\n",
      "Collecting wget\n",
      "  Downloading wget-3.2.zip (10 kB)\n",
      "Collecting requests-toolbelt\n",
      "  Downloading requests_toolbelt-0.10.1-py2.py3-none-any.whl (54 kB)\n",
      "Requirement already satisfied: opencv-python>=4.1.2 in c:\\users\\dalli\\anaconda3\\lib\\site-packages (from roboflow) (4.6.0.66)\n",
      "Collecting python-dotenv\n",
      "  Downloading python_dotenv-1.0.0-py3-none-any.whl (19 kB)\n",
      "Requirement already satisfied: requests in c:\\users\\dalli\\anaconda3\\lib\\site-packages (from roboflow) (2.26.0)\n",
      "Requirement already satisfied: cycler==0.10.0 in c:\\users\\dalli\\anaconda3\\lib\\site-packages (from roboflow) (0.10.0)\n",
      "Requirement already satisfied: numpy>=1.18.5 in c:\\users\\dalli\\anaconda3\\lib\\site-packages (from roboflow) (1.20.3)\n",
      "Requirement already satisfied: PyYAML>=5.3.1 in c:\\users\\dalli\\anaconda3\\lib\\site-packages (from roboflow) (6.0)\n",
      "Requirement already satisfied: python-dateutil in c:\\users\\dalli\\anaconda3\\lib\\site-packages (from roboflow) (2.8.2)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\dalli\\anaconda3\\lib\\site-packages (from roboflow) (3.4.3)\n",
      "Collecting pyparsing==2.4.7\n",
      "  Using cached pyparsing-2.4.7-py2.py3-none-any.whl (67 kB)\n",
      "Requirement already satisfied: colorama in c:\\users\\dalli\\anaconda3\\lib\\site-packages (from tqdm>=4.41.0->roboflow) (0.4.4)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\dalli\\anaconda3\\lib\\site-packages (from requests->roboflow) (2.0.4)\n",
      "Building wheels for collected packages: wget\n",
      "  Building wheel for wget (setup.py): started\n",
      "  Building wheel for wget (setup.py): finished with status 'done'\n",
      "  Created wheel for wget: filename=wget-3.2-py3-none-any.whl size=9672 sha256=24c478f64ec738265951d9f42107263189cc3d92d661d50d9f18a3807fdec28c\n",
      "  Stored in directory: c:\\users\\dalli\\appdata\\local\\pip\\cache\\wheels\\04\\5f\\3e\\46cc37c5d698415694d83f607f833f83f0149e49b3af9d0f38\n",
      "Successfully built wget\n",
      "Installing collected packages: idna, pyparsing, wget, requests-toolbelt, python-dotenv, roboflow\n",
      "  Attempting uninstall: idna\n",
      "    Found existing installation: idna 3.2\n",
      "    Uninstalling idna-3.2:\n",
      "      Successfully uninstalled idna-3.2\n",
      "  Attempting uninstall: pyparsing\n",
      "    Found existing installation: pyparsing 3.0.4\n",
      "    Uninstalling pyparsing-3.0.4:\n",
      "      Successfully uninstalled pyparsing-3.0.4\n",
      "Successfully installed idna-2.10 pyparsing-2.4.7 python-dotenv-1.0.0 requests-toolbelt-0.10.1 roboflow-0.2.32 wget-3.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "conda-repo-cli 1.0.4 requires pathlib, which is not installed.\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "{\n    \"error\": {\n        \"message\": \"This API key does not exist (or has been revoked).\",\n        \"type\": \"OAuthException\",\n        \"hint\": \"You may retrieve your API key via the Roboflow Dashboard. Go to Account > Roboflow Keys to retrieve yours.\",\n        \"key\": \"unauthorized\"\n    }\n}",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_8452/480675926.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mroboflow\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mRoboflow\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mrf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mRoboflow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mapi_key\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"unauthorized\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0mproject\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mworkspace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"dan-vmm5z\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mproject\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"car-damage-coco-dataset\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mdataset\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mproject\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mversion\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m9\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdownload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"coco-segmentation\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\roboflow\\__init__.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, api_key, model_format, notebook)\u001b[0m\n\u001b[0;32m     79\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnotebook\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnotebook\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     80\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0monboarding\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 81\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mauth\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     82\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     83\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mauth\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\roboflow\\__init__.py\u001b[0m in \u001b[0;36mauth\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     82\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     83\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mauth\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 84\u001b[1;33m         \u001b[0mr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_key\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapi_key\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel_format\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnotebook\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     85\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     86\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mr\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"onboarding\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\roboflow\\__init__.py\u001b[0m in \u001b[0;36mcheck_key\u001b[1;34m(api_key, model, notebook, num_retries)\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mresponse\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstatus_code\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m401\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 34\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     35\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mresponse\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstatus_code\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;36m200\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: {\n    \"error\": {\n        \"message\": \"This API key does not exist (or has been revoked).\",\n        \"type\": \"OAuthException\",\n        \"hint\": \"You may retrieve your API key via the Roboflow Dashboard. Go to Account > Roboflow Keys to retrieve yours.\",\n        \"key\": \"unauthorized\"\n    }\n}"
     ]
    }
   ],
   "source": [
    "!pip install roboflow\n",
    "\n",
    "from roboflow import Roboflow\n",
    "rf = Roboflow(api_key=\"unauthorized\")\n",
    "project = rf.workspace(\"dan-vmm5z\").project(\"car-damage-coco-dataset\")\n",
    "dataset = project.version(9).download(\"coco-segmentation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-02T07:42:56.377343Z",
     "iopub.status.busy": "2022-01-02T07:42:56.376932Z",
     "iopub.status.idle": "2022-01-02T07:42:56.381463Z",
     "shell.execute_reply": "2022-01-02T07:42:56.380617Z",
     "shell.execute_reply.started": "2022-01-02T07:42:56.377306Z"
    }
   },
   "outputs": [],
   "source": [
    "#/kaggle/input/car-scratch-dataset/car_dent_voc/car_dent_voc/valid/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-02T07:42:56.383271Z",
     "iopub.status.busy": "2022-01-02T07:42:56.382741Z",
     "iopub.status.idle": "2022-01-02T07:43:01.411025Z",
     "shell.execute_reply": "2022-01-02T07:43:01.410161Z",
     "shell.execute_reply.started": "2022-01-02T07:42:56.383233Z"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "\n",
    "import os\n",
    "import cv2\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator #\n",
    "from tensorflow.keras.preprocessing import image\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read data path and check files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-02T07:43:01.414232Z",
     "iopub.status.busy": "2022-01-02T07:43:01.413407Z",
     "iopub.status.idle": "2022-01-02T07:43:01.419582Z",
     "shell.execute_reply": "2022-01-02T07:43:01.418829Z",
     "shell.execute_reply.started": "2022-01-02T07:43:01.414192Z"
    }
   },
   "outputs": [],
   "source": [
    "train_data_path = \"../input/car-scratch-dataset/car_dent_coco/car_dent_coco/train/\"\n",
    "test_data_path = \"../input/car-scratch-dataset/car_dent_coco/car_dent_coco/test/\"\n",
    "valid_data_path = \"../input/car-scratch-dataset/car_dent_coco/car_dent_coco/valid/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-02T07:43:01.422589Z",
     "iopub.status.busy": "2022-01-02T07:43:01.42232Z",
     "iopub.status.idle": "2022-01-02T07:43:01.43886Z",
     "shell.execute_reply": "2022-01-02T07:43:01.438205Z",
     "shell.execute_reply.started": "2022-01-02T07:43:01.422538Z"
    }
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "# print(glob.glob(str(train_data_path)+'/*.jpg'))\n",
    "#back_light-1---83-_jpg.rf.829f6df0f7e1032fac163a84da29a75e.jpg\n",
    "#sign_light--19-_jpg.rf.9170ffdd1abc3028910d4592a6aa9984.jpg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-02T07:43:01.44065Z",
     "iopub.status.busy": "2022-01-02T07:43:01.440369Z",
     "iopub.status.idle": "2022-01-02T07:43:01.787916Z",
     "shell.execute_reply": "2022-01-02T07:43:01.78725Z",
     "shell.execute_reply.started": "2022-01-02T07:43:01.440612Z"
    }
   },
   "outputs": [],
   "source": [
    "# looking into the the data\n",
    "img = plt.imread(os.path.join(train_data_path, \"back_light-1---83-_jpg.rf.829f6df0f7e1032fac163a84da29a75e.jpg\"))\n",
    "plt.imshow(img)\n",
    "height, width, dim = img.shape\n",
    "print(\"size of image (h x w)\",height,width)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-02T07:43:01.78912Z",
     "iopub.status.busy": "2022-01-02T07:43:01.788888Z",
     "iopub.status.idle": "2022-01-02T07:43:02.077233Z",
     "shell.execute_reply": "2022-01-02T07:43:02.076587Z",
     "shell.execute_reply.started": "2022-01-02T07:43:01.789089Z"
    }
   },
   "outputs": [],
   "source": [
    "# looking into the the data\n",
    "img = plt.imread(os.path.join(train_data_path, \"sign_light--19-_jpg.rf.9170ffdd1abc3028910d4592a6aa9984.jpg\"))\n",
    "plt.imshow(img)\n",
    "height, width, dim = img.shape\n",
    "print(\"size of image (h x w)\",height,width)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-02T07:43:02.079048Z",
     "iopub.status.busy": "2022-01-02T07:43:02.078607Z",
     "iopub.status.idle": "2022-01-02T07:43:02.084249Z",
     "shell.execute_reply": "2022-01-02T07:43:02.083583Z",
     "shell.execute_reply.started": "2022-01-02T07:43:02.079012Z"
    }
   },
   "outputs": [],
   "source": [
    "train_data_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load images data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-02T07:43:02.086171Z",
     "iopub.status.busy": "2022-01-02T07:43:02.085625Z",
     "iopub.status.idle": "2022-01-02T07:43:06.393391Z",
     "shell.execute_reply": "2022-01-02T07:43:06.392632Z",
     "shell.execute_reply.started": "2022-01-02T07:43:02.086132Z"
    }
   },
   "outputs": [],
   "source": [
    "# train = ImageDataGenerator(rescale=1/255)\n",
    "# test = ImageDataGenerator(rescale=1/255)\n",
    "train = ImageDataGenerator(rescale=1/255)\n",
    "test = ImageDataGenerator(rescale=1/255)\n",
    "valid = ImageDataGenerator(rescale=1/255)\n",
    "\n",
    "img_width, img_height = 640, 640\n",
    "\n",
    "nb_train_samples = 2000\n",
    "nb_validation_samples = 800\n",
    "nb_epoch = 50\n",
    "\n",
    "train_dataset = train.flow_from_directory(directory = '../input/car-scratch-dataset/car_dent_coco/car_dent_coco/',classes = ['train']\n",
    "                                         ,\n",
    "        target_size=(img_width, img_height),\n",
    "        batch_size=32,\n",
    "        class_mode='binary')\n",
    "                                         \n",
    "test_dataset = test.flow_from_directory(directory = '../input/car-scratch-dataset/car_dent_coco/car_dent_coco/',classes = ['test']\n",
    "                                       ,\n",
    "        target_size=(img_width, img_height),\n",
    "        batch_size=16,\n",
    "        class_mode='binary')\n",
    "\n",
    "valid_dataset = test.flow_from_directory(directory = '../input/car-scratch-dataset/car_dent_coco/car_dent_coco/',classes = ['valid']\n",
    "                                        ,\n",
    "        target_size=(img_width, img_height),\n",
    "        batch_size=16,\n",
    "        class_mode='binary',\n",
    "        shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-02T07:43:06.39585Z",
     "iopub.status.busy": "2022-01-02T07:43:06.395595Z",
     "iopub.status.idle": "2022-01-02T07:43:06.402926Z",
     "shell.execute_reply": "2022-01-02T07:43:06.401915Z",
     "shell.execute_reply.started": "2022-01-02T07:43:06.395815Z"
    }
   },
   "outputs": [],
   "source": [
    "train_dataset.class_indices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-02T07:43:06.404707Z",
     "iopub.status.busy": "2022-01-02T07:43:06.404283Z",
     "iopub.status.idle": "2022-01-02T07:43:06.410943Z",
     "shell.execute_reply": "2022-01-02T07:43:06.410203Z",
     "shell.execute_reply.started": "2022-01-02T07:43:06.404667Z"
    }
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Convolution2D, MaxPooling2D\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-02T07:43:06.412446Z",
     "iopub.status.busy": "2022-01-02T07:43:06.412149Z",
     "iopub.status.idle": "2022-01-02T07:43:08.781335Z",
     "shell.execute_reply": "2022-01-02T07:43:08.780632Z",
     "shell.execute_reply.started": "2022-01-02T07:43:06.41241Z"
    }
   },
   "outputs": [],
   "source": [
    "# dimensions of our images.\n",
    "img_width, img_height = 640, 640\n",
    "\n",
    "nb_train_samples = 2000\n",
    "nb_validation_samples = 800\n",
    "nb_epoch = 50\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Convolution2D(32, (3, 3),padding='same',input_shape=(img_width, img_height,3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Convolution2D(32,(3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Convolution2D(32, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-02T07:43:08.783685Z",
     "iopub.status.busy": "2022-01-02T07:43:08.78318Z",
     "iopub.status.idle": "2022-01-02T07:43:08.798453Z",
     "shell.execute_reply": "2022-01-02T07:43:08.797694Z",
     "shell.execute_reply.started": "2022-01-02T07:43:08.783647Z"
    }
   },
   "outputs": [],
   "source": [
    "from keras.layers import Dense,Activation,Dropout, Conv2D, MaxPool2D\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "earlystop = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=1, min_delta=0.001)\n",
    "modelcheck = ModelCheckpoint('best_model.hdf5', monitor='val_accuracy',verbose=1,save_best_only=True,mode='max')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-02T07:43:08.802645Z",
     "iopub.status.busy": "2022-01-02T07:43:08.802438Z",
     "iopub.status.idle": "2022-01-02T07:45:51.649823Z",
     "shell.execute_reply": "2022-01-02T07:45:51.649146Z",
     "shell.execute_reply.started": "2022-01-02T07:43:08.802619Z"
    }
   },
   "outputs": [],
   "source": [
    "history = model.fit(train_dataset, \n",
    "                    validation_data=test_dataset,\n",
    "                    epochs=64,\n",
    "                    callbacks=[earlystop,modelcheck],\n",
    "                    batch_size=32)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-02T07:45:51.651587Z",
     "iopub.status.busy": "2022-01-02T07:45:51.651327Z",
     "iopub.status.idle": "2022-01-02T07:45:51.968162Z",
     "shell.execute_reply": "2022-01-02T07:45:51.967417Z",
     "shell.execute_reply.started": "2022-01-02T07:45:51.651538Z"
    }
   },
   "outputs": [],
   "source": [
    "model.save('car_model.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-02T07:45:51.969872Z",
     "iopub.status.busy": "2022-01-02T07:45:51.969627Z",
     "iopub.status.idle": "2022-01-02T07:45:52.09021Z",
     "shell.execute_reply": "2022-01-02T07:45:52.089494Z",
     "shell.execute_reply.started": "2022-01-02T07:45:51.969838Z"
    }
   },
   "outputs": [],
   "source": [
    "# Saving the model for Future Inferences\n",
    "\n",
    "model_json = model.to_json()\n",
    "with open(\"model.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "# serialize weights to HDF5\n",
    "model.save_weights(\"model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-02T07:45:52.091665Z",
     "iopub.status.busy": "2022-01-02T07:45:52.091381Z",
     "iopub.status.idle": "2022-01-02T07:45:52.248725Z",
     "shell.execute_reply": "2022-01-02T07:45:52.247988Z",
     "shell.execute_reply.started": "2022-01-02T07:45:52.091627Z"
    }
   },
   "outputs": [],
   "source": [
    "# imports\n",
    "\n",
    "\n",
    "# opening and store file in a variable\n",
    "\n",
    "json_file = open('model.json','r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "\n",
    "# use Keras model_from_json to make a loaded model\n",
    "\n",
    "loaded_model = tf.keras.models.model_from_json(loaded_model_json)\n",
    "\n",
    "# load weights into new model\n",
    "\n",
    "loaded_model.load_weights(\"model.h5\")\n",
    "print(\"Loaded Model from disk\")\n",
    "\n",
    "# compile and evaluate loaded model\n",
    "\n",
    "loaded_model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-02T07:45:52.250642Z",
     "iopub.status.busy": "2022-01-02T07:45:52.249936Z",
     "iopub.status.idle": "2022-01-02T07:45:52.254535Z",
     "shell.execute_reply": "2022-01-02T07:45:52.25363Z",
     "shell.execute_reply.started": "2022-01-02T07:45:52.250592Z"
    }
   },
   "outputs": [],
   "source": [
    "# from flask import Flask, render_template, request\n",
    "\n",
    "# @app.route('/')\n",
    "# def index_view():\n",
    "#     return render_template('index.html')\n",
    "\n",
    "\n",
    "# @app.route('/predict/',methods=['GET','POST'])\n",
    "# def predict():\n",
    "#     response = \"For ML Prediction\"\n",
    "#     return response\n",
    "\n",
    "# if __name__ == '__main__':\n",
    "#     app.run(debug=True, port=8000)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-02T07:45:52.256987Z",
     "iopub.status.busy": "2022-01-02T07:45:52.256081Z",
     "iopub.status.idle": "2022-01-02T07:45:52.265892Z",
     "shell.execute_reply": "2022-01-02T07:45:52.26505Z",
     "shell.execute_reply.started": "2022-01-02T07:45:52.256947Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_model():\n",
    "    global model\n",
    "    model = load_model('car_model')\n",
    "    print(\"Model loaded!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-02T07:45:52.267901Z",
     "iopub.status.busy": "2022-01-02T07:45:52.267055Z",
     "iopub.status.idle": "2022-01-02T07:45:52.277537Z",
     "shell.execute_reply": "2022-01-02T07:45:52.27668Z",
     "shell.execute_reply.started": "2022-01-02T07:45:52.267861Z"
    }
   },
   "outputs": [],
   "source": [
    "def load_image(img_path):\n",
    "\n",
    "    img = image.load_img(img_path)\n",
    "    img_tensor = image.img_to_array(img)                    # (height, width, channels)\n",
    "    img_tensor = np.expand_dims(img_tensor, axis=0)         # (1, height, width, channels), add a dimension because the model expects this shape: (batch_size, height, width, channels)\n",
    "    img_tensor /= 255.                                      # imshow expects values in the range [0, 1]\n",
    "\n",
    "    return img_tensor\n",
    "\n",
    "def prediction(img_path):\n",
    "    new_image = load_image(img_path)\n",
    "    \n",
    "    pred = model.predict(new_image)\n",
    "    \n",
    "    print(pred)\n",
    "    \n",
    "    labels=np.array(pred)\n",
    "    labels[labels>=0.6]=1\n",
    "    labels[labels<0.6]=0\n",
    "    \n",
    "    print(labels)\n",
    "    final=np.array(labels)\n",
    "    \n",
    "    if final[0][0]==1:\n",
    "        return \"Bad\"\n",
    "    else:\n",
    "        return \"Good\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-02T07:45:52.279424Z",
     "iopub.status.busy": "2022-01-02T07:45:52.27909Z",
     "iopub.status.idle": "2022-01-02T07:45:52.47226Z",
     "shell.execute_reply": "2022-01-02T07:45:52.471611Z",
     "shell.execute_reply.started": "2022-01-02T07:45:52.279387Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.plot(history.history['loss'], label='train') \n",
    "plt.plot(history.history['val_loss'], label='test') \n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-02T07:45:52.474083Z",
     "iopub.status.busy": "2022-01-02T07:45:52.473634Z",
     "iopub.status.idle": "2022-01-02T07:45:52.479735Z",
     "shell.execute_reply": "2022-01-02T07:45:52.478961Z",
     "shell.execute_reply.started": "2022-01-02T07:45:52.474045Z"
    }
   },
   "outputs": [],
   "source": [
    "print('Test accuracy achieved', history.history['val_accuracy'][-2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-02T07:45:52.481379Z",
     "iopub.status.busy": "2022-01-02T07:45:52.480954Z",
     "iopub.status.idle": "2022-01-02T07:46:03.523294Z",
     "shell.execute_reply": "2022-01-02T07:46:03.522619Z",
     "shell.execute_reply.started": "2022-01-02T07:45:52.481341Z"
    }
   },
   "outputs": [],
   "source": [
    "model.evaluate_generator(generator=valid_dataset,\n",
    "steps=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict the output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-02T07:46:03.524945Z",
     "iopub.status.busy": "2022-01-02T07:46:03.524528Z",
     "iopub.status.idle": "2022-01-02T07:46:05.213102Z",
     "shell.execute_reply": "2022-01-02T07:46:05.2124Z",
     "shell.execute_reply.started": "2022-01-02T07:46:03.524909Z"
    }
   },
   "outputs": [],
   "source": [
    "test_dataset.reset()\n",
    "pred=model.predict_generator(test_dataset,\n",
    "steps=128,\n",
    "verbose=1)\n",
    "predicted_class_indices=np.argmax(pred,axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-02T07:46:05.216432Z",
     "iopub.status.busy": "2022-01-02T07:46:05.216063Z",
     "iopub.status.idle": "2022-01-02T07:46:05.222922Z",
     "shell.execute_reply": "2022-01-02T07:46:05.221804Z",
     "shell.execute_reply.started": "2022-01-02T07:46:05.216402Z"
    }
   },
   "outputs": [],
   "source": [
    "predicted_class_indices\n",
    "\n",
    "# 0 = car damage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-02T07:46:05.224821Z",
     "iopub.status.busy": "2022-01-02T07:46:05.224125Z",
     "iopub.status.idle": "2022-01-02T07:46:05.232865Z",
     "shell.execute_reply": "2022-01-02T07:46:05.23202Z",
     "shell.execute_reply.started": "2022-01-02T07:46:05.224782Z"
    }
   },
   "outputs": [],
   "source": [
    "labels = (train_dataset.class_indices)\n",
    "labels = dict((v,k) for k,v in labels.items())\n",
    "predictions = [labels[k] for k in predicted_class_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-02T07:46:05.234691Z",
     "iopub.status.busy": "2022-01-02T07:46:05.234125Z",
     "iopub.status.idle": "2022-01-02T07:46:05.248753Z",
     "shell.execute_reply": "2022-01-02T07:46:05.247914Z",
     "shell.execute_reply.started": "2022-01-02T07:46:05.23465Z"
    }
   },
   "outputs": [],
   "source": [
    "filenames=test_dataset.filenames\n",
    "results=pd.DataFrame({\"Filename\":filenames,\n",
    "                      \"Predictions\":predictions})\n",
    "results.to_csv(\"results.csv\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validate Model Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-02T07:46:05.252432Z",
     "iopub.status.busy": "2022-01-02T07:46:05.251988Z",
     "iopub.status.idle": "2022-01-02T07:46:05.258562Z",
     "shell.execute_reply": "2022-01-02T07:46:05.257745Z",
     "shell.execute_reply.started": "2022-01-02T07:46:05.2524Z"
    }
   },
   "outputs": [],
   "source": [
    "#Check data in validation dataset\n",
    "import glob\n",
    "# print(glob.glob(str(valid_data_path)+'/*.jpg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-02T07:46:05.261995Z",
     "iopub.status.busy": "2022-01-02T07:46:05.261314Z",
     "iopub.status.idle": "2022-01-02T07:46:05.703127Z",
     "shell.execute_reply": "2022-01-02T07:46:05.702417Z",
     "shell.execute_reply.started": "2022-01-02T07:46:05.261933Z"
    }
   },
   "outputs": [],
   "source": [
    "# Our predict function\n",
    "def predictImage(filename):\n",
    "    \n",
    "    img = image.load_img(filename)\n",
    "    plt.imshow(img)\n",
    "    \n",
    "    Y = image.img_to_array(img)\n",
    "    X = np.expand_dims(Y,axis=0)\n",
    "    val = model.predict(X)\n",
    "    print(val)\n",
    "    if val < 0.5:\n",
    "        plt.xlabel(\"Car Damage\",fontsize=30)\n",
    "    elif val >= 0.5:\n",
    "        plt.xlabel(\"Car Not Damage\",fontsize=30)\n",
    "        \n",
    "        \n",
    "u = '../input/car-scratch-dataset/car_dent_coco/car_dent_coco/valid/rear_bumper-sep23---60-_jpg.rf.f20c9aeb3fa88e632b275bfccd7fdf4c.jpg'\n",
    "predictImage(u)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deploy the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-02T07:46:05.704794Z",
     "iopub.status.busy": "2022-01-02T07:46:05.704501Z",
     "iopub.status.idle": "2022-01-02T07:46:34.229792Z",
     "shell.execute_reply": "2022-01-02T07:46:34.228962Z",
     "shell.execute_reply.started": "2022-01-02T07:46:05.704744Z"
    }
   },
   "outputs": [],
   "source": [
    "!pip install fastapi uvicorn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-02T07:46:34.231988Z",
     "iopub.status.busy": "2022-01-02T07:46:34.231715Z",
     "iopub.status.idle": "2022-01-02T07:46:34.708008Z",
     "shell.execute_reply": "2022-01-02T07:46:34.707284Z",
     "shell.execute_reply.started": "2022-01-02T07:46:34.231951Z"
    }
   },
   "outputs": [],
   "source": [
    "from pydantic import BaseModel\n",
    "from fastapi import FastAPI\n",
    "import uvicorn\n",
    "\n",
    "app = FastAPI()\n",
    " \n",
    "\n",
    "class request_body(BaseModel):\n",
    "    f_name: str\n",
    "\n",
    "# Creating an Endpoint to receive the data\n",
    "# to make prediction on.\n",
    "@app.post('/predict')\n",
    "def predict(data : request_body):\n",
    "    # Making the data in a form suitable for prediction\n",
    "        \n",
    "    img = image.load_img(filename)\n",
    "    plt.imshow(img)\n",
    "    \n",
    "    Y = image.img_to_array(img)\n",
    "    X = np.expand_dims(Y,axis=0)\n",
    "    val = model.predict(X)\n",
    "    print(val)\n",
    "    if val < 0.5:\n",
    "        plt.xlabel(\"Car Damage\",fontsize=30)\n",
    "    elif val >= 0.5:\n",
    "        plt.xlabel(\"Car Not Damage\",fontsize=30)\n",
    "    return { 'class' : iris.target_names[class_idx]}\n",
    "    \n",
    "\n",
    "     \n",
    "    # Return the Result\n",
    "#     return { 'class' : iris.target_names[class_idx]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# StreamLit Web app"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-02T07:50:37.178602Z",
     "iopub.status.busy": "2022-01-02T07:50:37.177757Z"
    }
   },
   "outputs": [],
   "source": [
    "!pip install --upgrade streamlit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import streamlit as st\n",
    "import tensorflow as tf\n",
    "from PIL import Image, ImageOps\n",
    "def import_and_predict(image_data, model):\n",
    "    \n",
    "        size = (150,150) \n",
    "        image = ImageOps.fit(image_data)\n",
    "#         image = ImageOps.fit(image_data, size, Image.ANTIALIAS)\n",
    "        image = np.asarray(image)\n",
    "        image = (image.astype(np.float32) / 255.0)\n",
    "\n",
    "        img_reshape = image[np.newaxis,...]\n",
    "#         img = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "#         img_resize = (cv2.resize(img, dsize=(75, 75),    interpolation=cv2.INTER_CUBIC))/255.\n",
    "        \n",
    "#         img_reshape = img_resize[np.newaxis,...]\n",
    "    \n",
    "        prediction = model.predict(img_reshape)\n",
    "        \n",
    "        return prediction\n",
    "    \n",
    "model = tf.keras.models.load_model('car_model.hdf5')\n",
    "\n",
    "import streamlit as st\n",
    "st.write(\"\"\"\n",
    "         # Car Damage Detection\n",
    "         \"\"\"\n",
    "         )\n",
    "st.write(\"This is a simple image classification web app to predict damage\")\n",
    "file = st.file_uploader(\"Please upload an image file\", type=[\"jpg\", \"png\"])    \n",
    "if file is None:\n",
    "    st.text(\"Please upload an image file\")\n",
    "else:\n",
    "    image = Image.open(file)\n",
    "    st.image(image, use_column_width=True)\n",
    "    prediction = import_and_predict(image, model)\n",
    "    \n",
    "    if np.argmax(prediction) < 0.5:\n",
    "        st.write(\"Car Damage!\")\n",
    "    elif np.argmax(prediction) >= 0.5:\n",
    "        st.write(\"Car Not Damage!\")\n",
    "    \n",
    "    \n",
    "    st.text(\"Probability (0: Car_Damage, 1: Car_Not_Damage\")\n",
    "    st.write(prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References\n",
    "\n",
    "*    [Tutorial-image-classification-with-keras-flow-from-directory-and-generators](https://vijayabhaskar96.medium.com/tutorial-image-classification-with-keras-flow-from-directory-and-generators-95f75ebe5720)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
